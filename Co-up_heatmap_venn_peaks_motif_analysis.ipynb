{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hong's job description\n",
    "\n",
    "Attached please find the venn diagrams we generated based on the lists your provided, I also sent you the shared enhanced binding gene lists for both FC>1.2 (333 genes) and FC>1.5 (87 genes). Please generate TSS centered heatmaps for these two list genes respectively. Also include Y78A in these heatmaps. The dark blue color we usually use for Flag ChIP peaks would be good.\n",
    "\n",
    "At the meantime, you can help to generate venn diagram for WT, T1, T2 and T3, and the heatmaps for co-up peaks.\n",
    "\n",
    "For the motif analysis, please analysis the following four groups of genes: (1) 333 genes with FC>1.2 enhanced binding; (2) 87 genes with FC>1.5 enhanced binding; (3) T3 vs.WT FC>1.5 enhanced binding. For this three, please find enriched motifs in TSS +/- 2kb region. And then (4) look for enriched motifs in wild type ENL binding peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Heatmap for subgroup genes\n",
    "\n",
    "get the TSS TES gene lists\n",
    "\n",
    "reffile = '/mount/weili3/xc3/genomes/hg19.refGene.txt'\n",
    "\n",
    "convert the reffile to the tss tes gene lists using awk\n",
    "```shell\n",
    "awk 'BEGIN{OFS=\"\\t\"}{print $3, $5, $6, $13, \".\", $4}' /mount/weili3/xc3/genomes/hg19.refGene.txt > hg19.tss.tes.txt\n",
    "```\n",
    "remove the genes which are not on the chr1 - chr22 chrX chrY\n",
    "```shell\n",
    "awk '{if ($1 !~ /[_]/) print $0}' hg19.tss.tes.txt > hg19.tss.tes.trim.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Generate the bed file for the coup genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_coup_peaks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "os.chdir('/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>tss</th>\n",
       "      <th>tes</th>\n",
       "      <th>gene</th>\n",
       "      <th>dot</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOX4</th>\n",
       "      <td>chr11</td>\n",
       "      <td>89057521</td>\n",
       "      <td>89223909</td>\n",
       "      <td>NOX4</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C14orf166</th>\n",
       "      <td>chr14</td>\n",
       "      <td>52456227</td>\n",
       "      <td>52471420</td>\n",
       "      <td>C14orf166</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK3</th>\n",
       "      <td>chr9</td>\n",
       "      <td>4709556</td>\n",
       "      <td>4741309</td>\n",
       "      <td>AK3</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCM5</th>\n",
       "      <td>chr22</td>\n",
       "      <td>35796115</td>\n",
       "      <td>35820495</td>\n",
       "      <td>MCM5</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAXDC2</th>\n",
       "      <td>chr5</td>\n",
       "      <td>154198051</td>\n",
       "      <td>154230213</td>\n",
       "      <td>FAXDC2</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             chr        tss        tes       gene dot strand\n",
       "gene                                                        \n",
       "NOX4       chr11   89057521   89223909       NOX4   .      -\n",
       "C14orf166  chr14   52456227   52471420  C14orf166   .      +\n",
       "AK3         chr9    4709556    4741309        AK3   .      -\n",
       "MCM5       chr22   35796115   35820495       MCM5   .      +\n",
       "FAXDC2      chr5  154198051  154230213     FAXDC2   .      -"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genes = pd.read_csv('hg19.tss.tes.trim.txt', sep='\\t', \n",
    "                       header=None, names=['chr', 'tss','tes','gene','dot','strand'],\n",
    "                      dtype={1:np.int64,2:np.int64})\n",
    "# drop duplicates\n",
    "df_genes = df_genes.drop_duplicates(subset=['gene'])\n",
    "df_genes.index = df_genes.loc[:,'gene']\n",
    "df_genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chr          chr1\n",
       "tss       3547330\n",
       "tes       3566671\n",
       "gene       WRAP73\n",
       "dot             .\n",
       "strand          -\n",
       "Name: WRAP73, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genes.loc['WRAP73']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>tss</th>\n",
       "      <th>tes</th>\n",
       "      <th>gene</th>\n",
       "      <th>dot</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6-Mar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chr  tss  tes gene  dot strand\n",
       "gene                                 \n",
       "6-Mar  NaN  NaN  NaN  NaN  NaN    NaN"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_list = gene_lists[0]\n",
    "with open(gene_list, 'r') as f:\n",
    "    genes = f.readlines()\n",
    "    genes = [gene.rstrip() for gene in genes]\n",
    "df_sub = df_genes.reindex(genes)\n",
    "df_sub[df_sub.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the coup genes with tss tes\n",
    "gene_lists = ['T1_2_3 co-UP FC1.2.csv', 'T1_2_3 co-UP FC1.5.csv']\n",
    "names = ['1_2', '1_5']\n",
    "gene_list = gene_lists[0]\n",
    "for i, gene_list in enumerate(gene_lists):\n",
    "    with open(gene_list, 'r') as f:\n",
    "        genes = f.readlines()\n",
    "        genes = [gene.rstrip() for gene in genes]\n",
    "    df_genes.reindex(genes).to_csv(f'coup_{names[i]}.bed', sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change all the 'strand' to '+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3,$4,$5,\"+\"}' coup_1_2.bed > coup_1_2.plus.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3,$4,$5,\"+\"}' coup_1_5.bed > coup_1_5.plus.bed\n"
     ]
    }
   ],
   "source": [
    "# for name in names:\n",
    "#     line = 'awk \\'BEGIN{OFS=\\\"\\\\t\\\"}{print $1,$2,$3,$4,$5,\\\"+\\\"}\\'' + f' coup_{name}.bed > coup_{name}.plus.bed'\n",
    "#     print(line)\n",
    "#     os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 extract the signal and plot the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/software/deeptools/bin/computeMatrix reference-point --referencePoint TSS -S /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw -R coup_1_2.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o 1_2.Ts.ENL.tss.gz -p 8 --sortUsingSamples 1 --outFileSortedRegions 1_2.sorted.bed\n",
      "~/software/deeptools/bin/computeMatrix reference-point --referencePoint TSS -S /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw -R coup_1_5.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o 1_5.Ts.ENL.tss.gz -p 8 --sortUsingSamples 1 --outFileSortedRegions 1_5.sorted.bed\n"
     ]
    }
   ],
   "source": [
    "# computing the tss signal\n",
    "bwpath = '/home/xc3/output/ENL2/ChIP/bw_nsp/'\n",
    "exp = '293'\n",
    "bwfiles = glob.glob(bwpath+exp+'*.bw')\n",
    "bwfiles.sort()\n",
    "bwfiles = bwfiles[:5]\n",
    "for name in names:\n",
    "    profile_bed = f'coup_{name}.bed'\n",
    "    line = '~/software/deeptools/bin/computeMatrix reference-point --referencePoint TSS -S {} -R {} --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o {}.Ts.ENL.tss.gz -p 8 --sortUsingSamples 1 --outFileSortedRegions {}.sorted.bed'.format(' '.join(bwfiles), profile_bed, '{}'.format(name), name)\n",
    "    print(line)\n",
    "    os.system(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotHeatmap --sortUsingSamples 1 -m 1_2.Ts.ENL.tss.gz -out 1_2.tss.pdf --outFileNameMatrix 1_2.heatmap.tss.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10\n",
      "plotHeatmap --sortUsingSamples 1 -m 1_5.Ts.ENL.tss.gz -out 1_5.tss.pdf --outFileNameMatrix 1_5.heatmap.tss.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10\n"
     ]
    }
   ],
   "source": [
    "# plot the heatmap\n",
    "for name in names:\n",
    "    line = 'plotHeatmap --sortUsingSamples 1 -m {}.Ts.ENL.tss.gz -out {}.tss.pdf --outFileNameMatrix {} --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10'.format(name, name, name+'.heatmap.tss.mat')\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the FC 1.5 heatmap shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-144-ed11eccf3690>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-144-ed11eccf3690>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    plotHeatmap --sortUsingSamples 1 -m 1_5.Ts.ENL.tss.gz -out 1_5.tss.pdf --outFileNameMatrix 1_5.heatmap.tss.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 5\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "plotHeatmap --sortUsingSamples 1 -m 1_5.Ts.ENL.tss.gz -out 1_5.tss.pdf --outFileNameMatrix 1_5.heatmap.tss.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate the signal table for the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_deeptools_gz_to_df(file_name):\n",
    "    \"\"\"\n",
    "    file_name: the deeptools computeMatrix output matrix gz file\n",
    "    caculate the avg signal per sample across all the bins\n",
    "    \"\"\"\n",
    "    with gzip.open(file_name, 'rt', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    line = lines[0]\n",
    "    a = line.split('@')[-1].split('\\\\')[0]\n",
    "    a = re.sub('true', 'True', a)\n",
    "    a = re.sub('false', 'False', a)\n",
    "    a = re.sub('null', 'False', a)    \n",
    "    info = eval(a)\n",
    "    with open(f'{file_name}.txt', 'w') as f:\n",
    "        f.writelines(lines[1:])\n",
    "\n",
    "    df = pd.read_csv(f'{file_name}.txt', sep='\\t', header=None) \n",
    "    for i, sample in enumerate(info['sample_labels']):\n",
    "        start = info['sample_boundaries'][i] + 6\n",
    "        end = info['sample_boundaries'][i+1] + 6    \n",
    "        df[sample] = df.iloc[:, start:end].mean(axis=1)\n",
    "\n",
    "    df.sort_values(by=[info['sample_labels'][0]], inplace=True, ascending=False)     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    df = convert_deeptools_gz_to_df(file_name = f'{name}.Ts.ENL.tss.gz')\n",
    "    df.iloc[:, [0,1,2,3,4,5,-5,-4,-3,-2,-1]].to_csv(f'{name}.tss.sig.txt', index=False, sep='\\t')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate the venn diagram for peaks for T1 T2 T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_venn_diagram\r\n"
     ]
    }
   ],
   "source": [
    "workPath = '/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_venn_diagram/'\n",
    "os.chdir(workPath)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.bed > 293_F_Y78A.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.bed > 293_F_T2.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed > 293_F_ENL.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.bed > 293_F_T1.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.bed > 293_F_T3.bed\n"
     ]
    }
   ],
   "source": [
    "exp = '293'\n",
    "bed_path = '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/'\n",
    "bedFiles = glob.glob(f'{bed_path}{exp}*nsp_peaks.bed')\n",
    "# extract the first three columns of the bed files\n",
    "for bedFile in bedFiles:\n",
    "    outFile = bedFile.split('/')[-1].split('.')[0]\n",
    "    line = \"awk \\'BEGIN{OFS=\\\"\\\\t\\\"}{print $1,$2,$3}\\'\" + f' {bedFile} > {outFile}.bed'\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ppn = [1, 1]\n",
    "memory = 4\n",
    "wait_time = [20, 00]\n",
    "quene = \"short\"\n",
    "files = glob.glob('*.bed')\n",
    "files.sort()\n",
    "files = files[:-1]\n",
    "names = [ifile.split('/')[-1].split('.')[0] for ifile in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['293_F_ENL.bed', '293_F_T1.bed', '293_F_T2.bed', '293_F_T3.bed']\n",
      "python /home/xc3/software/bed_overlap4.py -v 293_all.venn.pdf -i 293_all.venn.bed 293_F_ENL.bed 293_F_T1.bed 293_F_T2.bed 293_F_T3.bed \n"
     ]
    }
   ],
   "source": [
    "# open the initialization header for pbs and read the contents\n",
    "with open('/home/xc3/experiment/initial.pbs','r') as f:\n",
    "    pbs_header = f.readlines()\n",
    "\n",
    "# write each sample a pbs files\n",
    "experiment_name = \"{}.ato\".format('venn_diagram')\n",
    "with open(experiment_name,'w') as f:\n",
    "    pbs_initial = pbs_header[:]\n",
    "    # configuration for the experiments\n",
    "    # pbs_initial[1]::job name\n",
    "    pbs_initial[1] = pbs_initial[1].format('venn')\n",
    "    # pbs_initial[2]::nodes and ppn\n",
    "    pbs_initial[2] = pbs_initial[2].format(*nodes_ppn)\n",
    "    # pbs_initial[4]::memeroy\n",
    "    pbs_initial[4] = pbs_initial[4].format(memory)\n",
    "    # pbs_initial[5]::waiting time\n",
    "    pbs_initial[5] = pbs_initial[5].format(*wait_time)\n",
    "    # pbs_initial[11]::err output\n",
    "    pbs_initial[11] = pbs_initial[11].format('venn')\n",
    "    # pbs_initial[12]::log\n",
    "    pbs_initial[12] = pbs_initial[12].format('venn')\n",
    "    # pbs_initial[14]::quene\n",
    "    pbs_initial[14] = pbs_initial[14].format(quene)\n",
    "    \n",
    "    #write all the configurations into the pbs file\n",
    "    for line in pbs_initial:\n",
    "        f.write(line)\n",
    "    line = f'cd {workPath}'\n",
    "    f.write(line + '\\n')\n",
    "\n",
    "    treat_files = files\n",
    "    print(treat_files)\n",
    "    treat_files_format = '{} ' * len(treat_files)\n",
    "    treat_files_format = treat_files_format.format(*treat_files)\n",
    "    output_venn = '{}_all.venn.pdf'.format(exp)\n",
    "    output_bed = '{}_all.venn.bed'.format(exp)\n",
    "    line = 'python /home/xc3/software/bed_overlap4.py -v {} -i {} {}'.format(output_venn, output_bed, treat_files_format)\n",
    "    print(line)\n",
    "    f.write(line + '\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Heatmap for subgroup coup peaks\n",
    "\n",
    "The coup peaks comes from the venn analysis intersection from bedoverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_coup_peaks\r\n"
     ]
    }
   ],
   "source": [
    "workPath = '/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_coup_peaks/'\n",
    "os.chdir(workPath)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 extract the 1.2 / 1.5 peaks as bed files then use bedoverlap to get the intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths = [1.2, 1.5]\n",
    "names = ['1_2','1_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 12) --> 293_T1_WT.merge.counts.anno.pval.txt 1.2\n",
      "293_T1_WT.1_2.bed\n",
      "(2287, 12) --> 293_T2_WT.merge.counts.anno.pval.txt 1.2\n",
      "293_T2_WT.1_2.bed\n",
      "(3761, 12) --> 293_T3_WT.merge.counts.anno.pval.txt 1.2\n",
      "293_T3_WT.1_2.bed\n",
      "(109, 12) --> 293_T1_WT.merge.counts.anno.pval.txt 1.5\n",
      "293_T1_WT.1_5.bed\n",
      "(495, 12) --> 293_T2_WT.merge.counts.anno.pval.txt 1.5\n",
      "293_T2_WT.1_5.bed\n",
      "(1107, 12) --> 293_T3_WT.merge.counts.anno.pval.txt 1.5\n",
      "293_T3_WT.1_5.bed\n"
     ]
    }
   ],
   "source": [
    "peakFiles = glob.glob('*.pval.txt')\n",
    "peakFiles.sort()\n",
    "for th, name in zip(ths, names):\n",
    "    for peakFile in peakFiles:\n",
    "        peakDf = pd.read_csv(peakFile, sep='\\t', header=None, skiprows=[0])\n",
    "        subId = peakDf.iloc[:,4].div(peakDf.iloc[:,5]) >= th\n",
    "        print(peakDf[subId].shape,'-->', peakFile, f'{th}')\n",
    "        outFile = peakFile.split(\".\")[0] + f'.{name}.bed'\n",
    "        print(outFile)\n",
    "        peakDf[subId].iloc[:, [0,1,2]].to_csv(f'{outFile}', sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 find the T1 T2 T3 overlapped peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /home/xc3/software/bed_overlap3.py -v 293.all.1_2.venn.pdf -i 293.all.1_2.bed 293_T1_WT.1_2.bed 293_T2_WT.1_2.bed 293_T3_WT.1_2.bed\n",
      "python /home/xc3/software/bed_overlap3.py -v 293.all.1_5.venn.pdf -i 293.all.1_5.bed 293_T1_WT.1_5.bed 293_T2_WT.1_5.bed 293_T3_WT.1_5.bed\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    bedFiles = glob.glob(f'*{name}.bed')\n",
    "    outBed = f'293.all.{name}.bed'\n",
    "    outVenn = f'293.all.{name}.venn.pdf'\n",
    "    bed_files_format = ' '.join(bedFiles)\n",
    "    line = 'python /home/xc3/software/bed_overlap3.py -v {} -i {} {}'.format(outVenn, outBed, bed_files_format)\n",
    "    print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Redraw the venn diagram for the shared 1.2 1.5 peaks\n",
    "the results depends hong whether like it or not (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Extract the signal for heatmap\n",
    "using the previous above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR>1){print $1,$2,$3,\"none\",\".\",\"+\"}}' 293.all.1_2.bed > 293.all.1_2.heat.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR>1){print $1,$2,$3,\"none\",\".\",\"+\"}}' 293.all.1_5.bed > 293.all.1_5.heat.bed\n"
     ]
    }
   ],
   "source": [
    "#format the bed file into the bed file add three columns more; \n",
    "for name in names:\n",
    "    Bed = f'293.all.{name}.bed'\n",
    "    outBed = f'293.all.{name}.heat.bed'\n",
    "    line = \"awk 'BEGIN{OFS=\\\"\\\\t\\\"}{if (NR>1){print $1,$2,$3,\\\"none\\\",\\\".\\\",\\\"+\\\"}}'\" + f' {Bed} > {outBed}'\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293.all.1_2.bed\t\t\t      293_T2_WT.1_2.bed\r\n",
      "293.all.1_2.heat.bed\t\t      293_T2_WT.1_5.bed\r\n",
      "293.all.1_2.venn.pdf\t\t      293_T2_WT.merge.counts.anno.pval.txt\r\n",
      "293.all.1_5.bed\t\t\t      293_T2_WT.merge.counts.anno.txt\r\n",
      "293.all.1_5.heat.bed\t\t      293_T3_WT.1_2.bed\r\n",
      "293.all.1_5.venn.pdf\t\t      293_T3_WT.1_5.bed\r\n",
      "293_T1_WT.1_2.bed\t\t      293_T3_WT.merge.counts.anno.pval.txt\r\n",
      "293_T1_WT.1_5.bed\t\t      293_T3_WT.merge.counts.anno.txt\r\n",
      "293_T1_WT.merge.counts.anno.pval.txt  293_all.venn.bed\r\n",
      "293_T1_WT.merge.counts.anno.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bin size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/software/deeptools/bin/computeMatrix reference-point --referencePoint center -S /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw -R 293.all.1_2.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o 1_2.Ts.ENL.peak.gz -p 8\n",
      "~/software/deeptools/bin/computeMatrix reference-point --referencePoint center -S /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw -R 293.all.1_5.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o 1_5.Ts.ENL.peak.gz -p 8\n"
     ]
    }
   ],
   "source": [
    "bwpath = '/home/xc3/output/ENL2/ChIP/bw_nsp/'\n",
    "exp = '293'\n",
    "bwfiles = glob.glob(bwpath+exp+'*.bw')\n",
    "bwfiles.sort()\n",
    "bwfiles = bwfiles[:5]\n",
    "for name in names:\n",
    "    outBed = f'293.all.{name}.heat.bed'\n",
    "    line = '~/software/deeptools/bin/computeMatrix reference-point --referencePoint center -S {} -R {} --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o {}.Ts.ENL.peak.gz -p 8'.format(' '.join(bwfiles), outBed, '{}'.format(name))\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotHeatmap --sortUsingSamples 1 -m 1_2.Ts.ENL.peak.gz -out 1_2.peak.pdf --outFileNameMatrix 1_2.heatmap.peak.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center\n",
      "plotHeatmap --sortUsingSamples 1 -m 1_5.Ts.ENL.peak.gz -out 1_5.peak.pdf --outFileNameMatrix 1_5.heatmap.peak.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center\n"
     ]
    }
   ],
   "source": [
    "# plot the heatmap\n",
    "for name in names:\n",
    "    line = 'plotHeatmap --sortUsingSamples 1 -m {}.Ts.ENL.peak.gz -out {}.peak.pdf --outFileNameMatrix {} --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center'.format(name, name, name+'.heatmap.peak.mat')\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replot the heatmap with shorter height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHeatmap --sortUsingSamples 1 -m 1_5.Ts.ENL.peak.gz -out 1_5.peak.pdf --outFileNameMatrix 1_5.heatmap.peak.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 5 --refPointLabel center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the table for the peak heatmap using peak center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    df = convert_deeptools_gz_to_df(file_name = f'{name}.Ts.ENL.peak.gz')\n",
    "    df.iloc[:, [0,1,2,3,4,5,-5,-4,-3,-2,-1]].to_csv(f'{name}.peak.sig.txt', index=False, sep='\\t') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add the delta heatmap for the above sampels\n",
    "Just heard back from Liling, actually she wants to change the delta heatmap color theme back to grey/black and orange that we used before. Could you please make this change for all the delta heatmap? In the FC >1.2 and FC>1.5 delta heatmap, right now we only have signals for wt, T1, T2 and T3, please add T1-wt, T2-wt and T3-wt. Attached is an old version of this figure for your reference, keep the blue color for individual sample, use the same organge-black/grey for delta map, but no need to label gene names on the right. **2018-8-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2.Ts.ENL.peak.gz  1_5.Ts.ENL.peak.gz\n",
      "1_2.peak.pdf   1_5.peak.pdf   293.all.1_2.venn.pdf\n",
      "1_2.peak1.pdf  1_5.peak1.pdf  293.all.1_5.venn.pdf\n"
     ]
    }
   ],
   "source": [
    "!ls *.gz\n",
    "!ls *.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the table for the peak region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for formating the chr start end into bed format\n",
    "# if the last column has sign ('+' or '-'), then prepare to swap tss and tes for '-'\n",
    "def convert_region_to_bed(bedfile, outname, header=None):\n",
    "    df = pd.read_csv(bedfile,sep='\\t',header=None)\n",
    "    df.columns = np.arange(0,df.shape[1])\n",
    "    # detect the strand and swap the start end when negative strand\n",
    "    # the last column should be strand\n",
    "    if df.iloc[0,-1] == '-' or df.iloc[0,-1] == '+':\n",
    "        idx = df.iloc[:,-1] == '-'\n",
    "        # swap the tss tes according to the strand\n",
    "        df.loc[idx,[1,2]] = df.loc[idx,[2,1]].values\n",
    "        # modify the strand\n",
    "        df.iloc[:,-1] = '+'\n",
    "        \n",
    "    df.loc[:,3] = np.arange(df.shape[0])# for gene name column\n",
    "    df.loc[:,4] = 0 # for bed format (value)\n",
    "    df.loc[:,5] = '+'\n",
    "    df = df.reindex(range(6), axis='columns')\n",
    "    print('writing the output --> {}'.format(outname))\n",
    "    print(f'{outname} --->: reformated bed_file as the input of the bigWigAverageoverBed')\n",
    "    df.to_csv(outname,sep='\\t',index=False,header=None)\n",
    "    \n",
    "    \n",
    "def comp_avg_sig_from_bw_by_bed(bedfile, bw_files, which_column=2):\n",
    "    \"\"\"\n",
    "    bedfile: the input merged bedfile which needs to extract the signal from\n",
    "    bw_files: list of bw files whose signal is extracted from\n",
    "    which_column: 3 is the acutal counts column, 4 is the acutal avg signal column;\n",
    "    but, we need to use the first column as index, then 2 is the counts column;\n",
    "    outname: reformat the bedfile to the normal 6 columns bed file\n",
    "    will save the output file in the same folder as the bedfile\n",
    "    \"\"\"\n",
    "    outname = bedfile.split('.bed')[0] + '.str.bed'\n",
    "    # convert the 3 columns bed to the normal bed file\n",
    "    convert_region_to_bed(bedfile, outname)\n",
    "    for i,bw_file in enumerate(bw_files):\n",
    "        command = line = f'~/software/bigWigAverageOverBed {bw_file} {outname} avg_sig_{i}.txt'\n",
    "        print('execute --> {}'.format(command))\n",
    "        os.system(command)\n",
    "    dfs = []\n",
    "    for i in range(len(bw_files)):\n",
    "        dfs.append(pd.read_csv(f'avg_sig_{i}.txt',sep='\\t',header=None, index_col=0))\n",
    "    df = pd.DataFrame([dfs[0].iloc[:,0]] + # iloc[:,0]: the width\n",
    "                      [dfi.iloc[:,which_column] for dfi in dfs]).T # conbine the columns together\n",
    "    df.columns = ['width'] + [bw_file.split('/')[-1].split('.')[0] for bw_file in bw_files]\n",
    "    df_bed = pd.read_csv(bedfile, sep='\\t', header=None, names = ['chr', 'start', 'end'])\n",
    "    df_out = df_bed.join(df)\n",
    "    print(f\"output file -->: {bedfile.split('.bed')[0] + '.counts.txt'}\")\n",
    "    df_out.to_csv(bedfile.split('.bed')[0] + '.counts.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate the signal for 293.all.1_2.bed\n",
      "writing the output --> 293.all.1_2.str.bed\n",
      "293.all.1_2.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw 293.all.1_2.str.bed avg_sig_0.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw 293.all.1_2.str.bed avg_sig_1.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw 293.all.1_2.str.bed avg_sig_2.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw 293.all.1_2.str.bed avg_sig_3.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw 293.all.1_2.str.bed avg_sig_4.txt\n",
      "output file -->: 293.all.1_2.counts.txt\n",
      "generate the signal for 293.all.1_5.bed\n",
      "writing the output --> 293.all.1_5.str.bed\n",
      "293.all.1_5.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw 293.all.1_5.str.bed avg_sig_0.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw 293.all.1_5.str.bed avg_sig_1.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw 293.all.1_5.str.bed avg_sig_2.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw 293.all.1_5.str.bed avg_sig_3.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw 293.all.1_5.str.bed avg_sig_4.txt\n",
      "output file -->: 293.all.1_5.counts.txt\n"
     ]
    }
   ],
   "source": [
    "bwpath = '/home/xc3/output/ENL2/ChIP/bw_nsp/'\n",
    "exp = '293'\n",
    "bwfiles = glob.glob(bwpath+exp+'*.bw')\n",
    "bwfiles.sort()\n",
    "bwfiles = bwfiles[:5]\n",
    "for name in names:\n",
    "    bed_file = f'{exp}.all.{name}.bed'\n",
    "    print('generate the signal for',bed_file)\n",
    "    comp_avg_sig_from_bw_by_bed(bed_file, bwfiles, 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-rank the file accordi ng to the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_row(row):\n",
    "    row = [str(ele) for ele in row]\n",
    "    return '|'.join(row)\n",
    "\n",
    "for name in names:\n",
    "    df1 = pd.read_csv(f'{name}.peak.sig.txt', sep='\\t')\n",
    "    df1.index = df1.iloc[:,:3].apply(combine_row, axis=1)\n",
    "    df2 = pd.read_csv(f'{exp}.all.{name}.counts.txt', sep='\\t')\n",
    "    df2.index = df2.iloc[:,:3].apply(combine_row, axis=1)\n",
    "    df2 = df2.reindex(df1.index)\n",
    "    df2.to_csv(f'{exp}.all.{name}.sig.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annoate_bed_to_gene(infile, outfile, cutoff=5000):\n",
    "    ref, tss_set = {}, set()\n",
    "    reffile = '/mount/weili3/xc3/genomes/hg19.refGene.txt'\n",
    "    for line in open(reffile):\n",
    "        col = line.split('\\t')\n",
    "        name, cr, strand, TSS, TES, symbol = col[1], col[2], col[3], int(col[4]), int(col[5]), col[12]\n",
    "        if strand == '-': TSS, TES = TES, TSS\n",
    "        if cr not in ref: ref[cr] = []\n",
    "        if (cr,TSS,strand) not in tss_set:\n",
    "            ref[cr].append((name,symbol,strand,TSS,TES))\n",
    "            tss_set.add((cr,TSS,strand))\n",
    "    for cr in ref: ref[cr].append(('none','none','none',0,0))\n",
    "    \n",
    "    # annotate the file\n",
    "    text = open(infile).readlines()\n",
    "    fout = open(outfile, 'w')\n",
    "    print('processing on {}\\n will output {}\\n'.format(infile,outfile))\n",
    "    for line in text:\n",
    "        col = line.split('\\t')\n",
    "        try: cr, start, end = col[0], int(col[1]), int(col[2])\n",
    "        except: \n",
    "            fout.write(line[:-1]+'\\twithin_genebody\\tnearest_TSS\\tdistance\\n')\n",
    "            continue\n",
    "        if cr not in ref: continue\n",
    "        peak = (start + end) / 2\n",
    "        genes, genebody, genes0, genebody0 = [], [], [], []\n",
    "        for name, symbol, strand, TSS, TES in ref[cr]:\n",
    "            if strand == '+':\n",
    "                dist = end - TSS\n",
    "                if abs(start-TSS)<abs(dist):dist=start-TSS\n",
    "\n",
    "            elif strand == '-':\n",
    "                dist = TSS - end\n",
    "                if abs(TSS - start)<abs(dist):dist=TSS - start\n",
    "\n",
    "            elif strand != 'none': raise ValueError\n",
    "            if abs(dist) <= cutoff: genes.append((abs(dist),symbol,dist)) \n",
    "            if (start - TSS) * (start - TES) <= 0: genebody.append((abs(dist),symbol,dist))\n",
    "            elif (end - TSS) * (end - TES) <= 0: genebody.append((abs(dist),symbol,dist))\n",
    "            elif (start - TSS) * (end - TES) <=0: genebody.append((abs(dist),symbol,dist))\n",
    "        genes, genebody = sorted(genes), sorted(genebody)\n",
    "        for g in sorted(genes):\n",
    "            if g[1] not in [x[1] for x in genes0]: genes0.append(g)\n",
    "        for g in sorted(genebody):\n",
    "            if g[1] not in [x[1] for x in genebody0]: genebody0.append(g)\n",
    "        if any(genes0):\n",
    "            symbols = ','.join([x[1] for x in genes0])\n",
    "            dists = ','.join(['%d' % x[2] for x in sorted(genes0)])\n",
    "        else: symbols, dists = 'none', 'none'\n",
    "        if any(genebody): body = ','.join([x[1] for x in genebody0])\n",
    "        else: body = 'none'\n",
    "        fout.write(line[:-1] + '\\t%s\\t%s\\t%s\\n' % (body,symbols,dists))\n",
    "    fout.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing on 293.all.1_2.sig.txt\n",
      " will output 293.all.1_2.sig.anno.txt\n",
      "\n",
      "processing on 293.all.1_5.sig.txt\n",
      " will output 293.all.1_5.sig.anno.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    annoate_bed_to_gene(f'{exp}.all.{name}.sig.txt', f'{exp}.all.{name}.sig.anno.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Motif analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1） 333 genes with FC>1.2 enhanced binding; 2）87 genes with FC>1.5; 3) T3 vs.WT FC>1.5 enhanced binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_motif\r\n"
     ]
    }
   ],
   "source": [
    "workPath = '/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_motif/'\n",
    "os.chdir(workPath)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 extract the sequence for the three gene lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process on T1_2_3 co-UP FC1.2.txt\n",
      "process on T1_2_3 co-UP FC1.5.txt\n",
      "process on 293_T3_WT.merge.counts.anno.genes1_5.txt\n"
     ]
    }
   ],
   "source": [
    "# read the gene's tss and tes and save to the bed file\n",
    "geneLists = ['T1_2_3 co-UP FC1.2.txt', 'T1_2_3 co-UP FC1.5.txt', '293_T3_WT.merge.counts.anno.genes1_5.txt']\n",
    "names = ['coup.1_2', 'coup.1_5', 'T3WT.1_5']\n",
    "gene_list = geneLists[0]\n",
    "for i, gene_list in enumerate(geneLists):\n",
    "    with open(gene_list, 'r') as f:\n",
    "        genes = f.readlines()\n",
    "        genes = [gene.rstrip() for gene in genes]\n",
    "        df = df_genes.reindex(genes)\n",
    "        df.loc[:,'strand'] = '+'\n",
    "        print(f'process on {gene_list}')\n",
    "        df['tes'] = df['tss'] + 2000\n",
    "        df['tss'] = df['tss'] - 2000\n",
    "        df.to_csv(f'{names[i]}.motif.bed', sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed coup.1_2.motif.bed -fo coup.1_2.motif.txt\n",
      "awk '!a[$0]++' coup.1_2.motif.txt > coup.1_2.motif.uniq.txt\n",
      "bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed coup.1_5.motif.bed -fo coup.1_5.motif.txt\n",
      "awk '!a[$0]++' coup.1_5.motif.txt > coup.1_5.motif.uniq.txt\n",
      "bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed T3WT.1_5.motif.bed -fo T3WT.1_5.motif.txt\n",
      "awk '!a[$0]++' T3WT.1_5.motif.txt > T3WT.1_5.motif.uniq.txt\n"
     ]
    }
   ],
   "source": [
    "# extract the sequence for the corrdinates\n",
    "for name in names:\n",
    "    bedFile = f'{name}.motif.bed'\n",
    "    outTxt = f'{name}.motif.txt'\n",
    "    line = f\"bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed {bedFile} -fo {outTxt}\"\n",
    "    print(line)\n",
    "    os.system(line)\n",
    "    line = \"awk \\'!a[$0]++\\'\" + f\" {outTxt} > {name}.motif.uniq.txt\"\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 look for enriched motifs in wild type ENL binding peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t858702\t861593\tMACS_peak_1\t1093.75\n",
      "chr1\t870327\t871455\tMACS_peak_2\t97.85\n",
      "chr1\t875392\t878559\tMACS_peak_3\t676.52\n",
      "chr1\t932422\t936620\tMACS_peak_4\t1067.60\n",
      "chr1\t955250\t956213\tMACS_peak_5\t86.76\n",
      "chr1\t1709153\t1710245\tMACS_peak_6\t94.82\n",
      "chr1\t1821251\t1822759\tMACS_peak_7\t346.39\n",
      "chr1\t2159906\t2163136\tMACS_peak_8\t1053.44\n",
      "chr1\t2245753\t2246888\tMACS_peak_9\t88.14\n",
      "chr1\t3568419\t3569644\tMACS_peak_10\t98.29\n",
      "3298 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed\n"
     ]
    }
   ],
   "source": [
    "!head /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed\n",
    "!wc -l /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed\n",
    "!cp /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed  ./\n",
    "!mv 293_F_ENL.nsp_peaks.bed ENL.motif.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed ENL.motif.bed -fo ENL.motif.txt\n",
      "awk '!a[$0]++' ENL.motif.txt > ENL.motif.uniq.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'ENL'\n",
    "bedFile = f'{name}.motif.bed'\n",
    "outTxt = f'{name}.motif.txt'\n",
    "line = f\"bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed {bedFile} -fo {outTxt}\"\n",
    "print(line)\n",
    "os.system(line)\n",
    "line = \"awk \\'!a[$0]++\\'\" + f\" {outTxt} > {name}.motif.uniq.txt\"\n",
    "print(line)\n",
    "os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_coup_peaks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "os.chdir('/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_coup_peaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test all the pre-binding peaks signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw',\n",
       " '/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw',\n",
       " '/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw',\n",
       " '/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw',\n",
       " '/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t8482987\t8484389\r\n",
      "chr1\t15943726\t15944596\r\n",
      "chr1\t16173761\t16176666\r\n",
      "chr1\t26734734\t26735700\r\n",
      "chr1\t27286358\t27287134\r\n",
      "chr1\t38229600\t38230601\r\n",
      "chr1\t57043618\t57045418\r\n",
      "chr1\t61547212\t61550060\r\n",
      "chr1\t65431315\t65432543\r\n",
      "chr1\t78097423\t78099183\r\n"
     ]
    }
   ],
   "source": [
    "treats = ['T1','T2','T3']\n",
    "treat = treats[0]\n",
    "ctrl = 'ENL'\n",
    "[glob.glob(bwpath+exp+'*'+treat+'*.bw')[0], glob.glob(bwpath+exp+'*'+ctrl+'*.bw')[0]]\n",
    "bed_file = f'{exp}_{treat}_WT.1_2.bed'\n",
    "!head $bed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate the signal for 293_T1_WT.1_2.bed\n",
      "writing the output --> 293_T1_WT.1_2.str.bed\n",
      "293_T1_WT.1_2.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw 293_T1_WT.1_2.str.bed avg_sig_0.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw 293_T1_WT.1_2.str.bed avg_sig_1.txt\n",
      "output file -->: 293_T1_WT.1_2.counts.txt\n",
      "********\n",
      "generate the signal for 293_T2_WT.1_2.bed\n",
      "writing the output --> 293_T2_WT.1_2.str.bed\n",
      "293_T2_WT.1_2.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw 293_T2_WT.1_2.str.bed avg_sig_0.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw 293_T2_WT.1_2.str.bed avg_sig_1.txt\n",
      "output file -->: 293_T2_WT.1_2.counts.txt\n",
      "********\n",
      "generate the signal for 293_T3_WT.1_2.bed\n",
      "writing the output --> 293_T3_WT.1_2.str.bed\n",
      "293_T3_WT.1_2.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw 293_T3_WT.1_2.str.bed avg_sig_0.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw 293_T3_WT.1_2.str.bed avg_sig_1.txt\n",
      "output file -->: 293_T3_WT.1_2.counts.txt\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "bwpath = '/home/xc3/output/ENL2/ChIP/bw_nsp/'\n",
    "exp = '293'\n",
    "bwfiles.sort()\n",
    "for treat in treats:\n",
    "    bed_file = f'{exp}_{treat}_WT.1_2.bed'\n",
    "    bwfiles = [glob.glob(bwpath+exp+'*'+treat+'*.bw')[0],\n",
    "          glob.glob(bwpath+exp+'*'+ctrl+'*.bw')[0]]\n",
    "    print('generate the signal for',bed_file)\n",
    "    comp_avg_sig_from_bw_by_bed(bed_file, bwfiles, 3)\n",
    "    print('********'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('1_2.peak.sig.txt', sep='\\t')\n",
    "df = pd.read_csv('293_T1_WT.1_2.counts.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fc'] = df.iloc[:,-2].div(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>width</th>\n",
       "      <th>293_F_T1_treat</th>\n",
       "      <th>293_F_ENL_treat</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chr, start, end, width, 293_F_T1_treat, 293_F_ENL_treat, fc]\n",
       "Index: []"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['fc'] < 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
