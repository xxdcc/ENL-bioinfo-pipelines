{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3 “the delta heatmap”, it is not only for peaks with more than 1.2-fold changes. Basically you will directly use the **pair-wise comparison signal files you sent to me on July 7th** to generate the delta heatmap, they are named as “**293_Ts_WT.merge.sig.anno.pval**”. Based on that table, you use FC1.2 as cutoff to group peaks into Up, No change, and Down subgroups. Just a reminder, since now we have already used local lamda and input to help with the peak calling, no need to compare to input signal to remove non-specific peaks any more. Then plot them for **peak centered 5 kb** plus/minus regions, similar to the delta heatmap you generated earlier (one example attached here). For the delta map part, use the color scheme Liling suggested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use the 293_Ts_WT.merge.sig.anno.pval in ./res_avg_sig\n",
    "* split the files into three groups **Note** the previous generated group (293.sig.anno) is it the same as the computeMatrix?\n",
    "* computeMatrix use the \"\\t\" seperated bed file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate the delta heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4dd487f98c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/'"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "treats = ['T1', 'T2', 'T3', 'Y78A']\n",
    "ctrl = 'ENL'\n",
    "# sigpath: store the previous generated merged peaks signal for T and wt\n",
    "sigpath = './res_avg_signal/' \n",
    "outpath = './res_delta_heatmap/'\n",
    "bwpath = '/home/xc3/output/ENL2/ChIP/bw_nsp/'\n",
    "exp = '293'\n",
    "treat = treats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> generate the bed file and use computeMatrix to generate the bin signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda\n",
      "chr\tstart\tend\twidth\t293_F_T1_treat\t293_F_ENL_treat\t293_ctrl\twithin_genebody\tnearest_TSS\tdistance\tlogFC\tPValue\n",
      "chr1\t858702\t861593\t2891.0\t20.479418886198548\t23.870632998962297\t3.969906606710482\tSAMD11\tSAMD11,LOC100130417\t473,-3630\t-0.221\t0.475\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "sigfile = f'{sigpath}293_{treat}_WT.merge.sig.anno.pval.txt'\n",
    "!head $sigfile -n2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the previous bigWig Generated signal to rank the split the peaks into three groups: upper, lower, nodiff\n",
    "Then, use this peak to extract the signal from bw using deeptools computeMatrix\n",
    "Finally, use the matrix to do the heatmap plot\n",
    "\n",
    "Bin size: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR > 1) print $1, $2, $3,\"none\",\".\", \"+\"}' ./res_avg_signal/293_T1_WT.merge.sig.anno.pval.txt > ./res_delta_heatmap/T1.bed\n",
      "****\n",
      "computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 50 --missingDataAsZero -R ./res_delta_heatmap/T1.bed -S /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw  --skipZeros -o ./res_delta_heatmap/293_T1_ENL.scale.gz --outFileNameMatrix ./res_delta_heatmap/293_T1_ENL.scale.txt \n",
      "\n",
      "\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR > 1) print $1, $2, $3,\"none\",\".\", \"+\"}' ./res_avg_signal/293_T2_WT.merge.sig.anno.pval.txt > ./res_delta_heatmap/T2.bed\n",
      "****\n",
      "computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 50 --missingDataAsZero -R ./res_delta_heatmap/T2.bed -S /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw  --skipZeros -o ./res_delta_heatmap/293_T2_ENL.scale.gz --outFileNameMatrix ./res_delta_heatmap/293_T2_ENL.scale.txt \n",
      "\n",
      "\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR > 1) print $1, $2, $3,\"none\",\".\", \"+\"}' ./res_avg_signal/293_T3_WT.merge.sig.anno.pval.txt > ./res_delta_heatmap/T3.bed\n",
      "****\n",
      "computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 50 --missingDataAsZero -R ./res_delta_heatmap/T3.bed -S /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw  --skipZeros -o ./res_delta_heatmap/293_T3_ENL.scale.gz --outFileNameMatrix ./res_delta_heatmap/293_T3_ENL.scale.txt \n",
      "\n",
      "\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR > 1) print $1, $2, $3,\"none\",\".\", \"+\"}' ./res_avg_signal/293_Y78A_WT.merge.sig.anno.pval.txt > ./res_delta_heatmap/Y78A.bed\n",
      "****\n",
      "computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 50 --missingDataAsZero -R ./res_delta_heatmap/Y78A.bed -S /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw  --skipZeros -o ./res_delta_heatmap/293_Y78A_ENL.scale.gz --outFileNameMatrix ./res_delta_heatmap/293_Y78A_ENL.scale.txt \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for treat in treats:\n",
    "    #1. extract the first three columns as the bed file\n",
    "    sigfile = f'{sigpath}293_{treat}_WT.merge.sig.anno.pval.txt'\n",
    "    line = \"awk \\'BEGIN{OFS=\\\"\\\\t\\\"}{if (NR > 1) print $1, $2, $3,NR-2,\\\".\\\", \\\"+\\\"}\\'\" + f' {sigfile} > {outpath}{treat}.bed'\n",
    "    print(line + '\\n****')\n",
    "    os.system(line)\n",
    "    # 2. use the bed file to extract the binning signal (center -5k~5k)\n",
    "    bw_files = [\n",
    "            glob.glob(bwpath + exp + '*' + tmp + '*.bw')[0]\n",
    "            for tmp in [treat, ctrl]\n",
    "    ]\n",
    "    bw_files_format = len(bw_files) * \"{} \"\n",
    "    bw_files_format = bw_files_format.format(*bw_files)\n",
    "    bed_file_format = f'{outpath}{treat}.bed'\n",
    "    command = \"computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 100 --missingDataAsZero -R {0} -S {1} --skipZeros -o {2}.scale.gz --outFileNameMatrix {3}.scale.txt \".format(\n",
    "    bed_file_format, bw_files_format,\n",
    "    outpath + exp + '_' + treat + '_' + ctrl,\n",
    "    outpath + exp + '_' + treat + '_' + ctrl)\n",
    "    print(command + '\\n\\n')\n",
    "    os.system(command)\n",
    "    os.system(\n",
    "        'rm {}.scale.gz'.format(outpath + exp + '_' + treat + '_' + ctrl))   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Split the group according to the previous f'{sigpath}293_{treat}_WT.merge.sig.anno.pval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_line_per_colname_center(colname, colnames, line):\n",
    "    eles = line.split('\\t')\n",
    "    vals = [\n",
    "        eles[id] for id, icolname in enumerate(colnames) if icolname == colname\n",
    "    ]\n",
    "    N = len(vals)\n",
    "    return np.mean(np.array(vals)[N // 4:N // 4 * 3].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use the computeMatrxi to extract the signal and then rank the signal by upper, lower and nodiff\n",
    "Which is Bad (removed in future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess --> ./res_delta_heatmap/293_T1_ENL.scale.txt\n",
      "preprocess --> ./res_delta_heatmap/293_T2_ENL.scale.txt\n",
      "preprocess --> ./res_delta_heatmap/293_T3_ENL.scale.txt\n",
      "preprocess --> ./res_delta_heatmap/293_Y78A_ENL.scale.txt\n"
     ]
    }
   ],
   "source": [
    "for treat in treats:\n",
    "    #5. calculate the averaged signal across all the samples\n",
    "    with open(\n",
    "            '{}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl), 'r') as f:\n",
    "        print('preprocess --> {}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl))\n",
    "        lines = f.readlines()\n",
    "        lines = lines[2:]\n",
    "        colnames = lines[0].rstrip().split('\\t')[1:]\n",
    "        colnames_uniq = np.unique(colnames)\n",
    "        idx = [\n",
    "            i for col in [treat, ctrl]\n",
    "            for i, ele in enumerate(colnames_uniq) if col in ele\n",
    "        ]\n",
    "        colnames_uniq = colnames_uniq[idx]\n",
    "        all_cols = []\n",
    "        for colname_uniq in colnames_uniq:\n",
    "            one_col = []\n",
    "            for line in lines[1:]:\n",
    "                one_col.append(\n",
    "                    average_line_per_colname_center(\n",
    "                        colname_uniq, colnames, line))\n",
    "            all_cols.append(one_col)\n",
    "        df = pd.DataFrame(np.array(all_cols).T, columns=colnames_uniq)\n",
    "        \n",
    "        # combine the peak location and signal\n",
    "        bed_file_format = f'{outpath}{treat}.bed'\n",
    "        df_anno = pd.read_csv(\n",
    "            bed_file_format,\n",
    "            sep='\\t',\n",
    "            header=None,\n",
    "            names=['chr', 'start', 'end', 'gene', 'info', 'strand'])\n",
    "        df_comb = pd.concat([df_anno, df], axis=1)\n",
    "        # remove the peaks which does not have significant signal two fold more than the ctrl\n",
    "        # df_sub = df_comb[(df_comb.iloc[:,3] + df_comb.iloc[:,4]) / df_comb.iloc[:,5] > 4]\n",
    "        df_sub = df_comb\n",
    "        #6. divide the peaks according to the enrichment into three groups\n",
    "        df_sub_upper = df_sub[\n",
    "            df_sub.iloc[:, -2].values / df_sub.iloc[:, -1].values > 1.5]\n",
    "        df_sub_lower = df_sub[\n",
    "            df_sub.iloc[:, -2].values / df_sub.iloc[:, -1].values < 1 / 1.5]\n",
    "        df_sub_nodiff = df_sub[\n",
    "            (df_sub.iloc[:, -2].values / df_sub.iloc[:, -1].values >= 1 / 1.5)\n",
    "            & (df_sub.iloc[:, -2].values / df_sub.iloc[:, -1].values <= 1.5)]\n",
    "        #7. save the upper lower and nodiff results as tables\n",
    "        df_sub_upper.to_csv(\n",
    "            '{}_{}_{}.average.upper.txt'.format(outpath+exp, treat, ctrl),\n",
    "            index=True,\n",
    "            sep='\\t')\n",
    "        df_sub_lower.to_csv(\n",
    "            '{}_{}_{}.average.lower.txt'.format(outpath+exp, treat, ctrl),\n",
    "            index=True,\n",
    "            sep='\\t')\n",
    "        df_sub_nodiff.to_csv(\n",
    "            '{}_{}_{}.average.nodiff.txt'.format(outpath+exp, treat, ctrl),\n",
    "            index=True,\n",
    "            sep='\\t')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the average peak signal as the rank list order for the delta heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess on ./res_avg_signal/293_T1_WT.merge.sig.anno.pval.txt\n",
      "upper***\n",
      "\n",
      "lower***\n",
      "\n",
      "nodiff***\n",
      "\n",
      "preprocess on ./res_avg_signal/293_T2_WT.merge.sig.anno.pval.txt\n",
      "upper***\n",
      "\n",
      "lower***\n",
      "\n",
      "nodiff***\n",
      "\n",
      "preprocess on ./res_avg_signal/293_T3_WT.merge.sig.anno.pval.txt\n",
      "upper***\n",
      "\n",
      "lower***\n",
      "\n",
      "nodiff***\n",
      "\n",
      "preprocess on ./res_avg_signal/293_Y78A_WT.merge.sig.anno.pval.txt\n",
      "upper***\n",
      "\n",
      "lower***\n",
      "\n",
      "nodiff***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc = 1.2\n",
    "for treat in treats:\n",
    "    sigfile = f'{sigpath}293_{treat}_WT.merge.sig.anno.pval.txt'\n",
    "    df = pd.read_csv(sigfile,sep='\\t',header=0)  \n",
    "    print('preprocess on {}'.format(sigfile))\n",
    "    exts = ['upper', 'lower', 'nodiff']\n",
    "    ind_up = df.iloc[:,4].div(df.iloc[:,5]) >= fc\n",
    "    ind_down = df.iloc[:,4].div(df.iloc[:,5]) <= (1.0/fc)\n",
    "    ind_no = (df.iloc[:,4].div(df.iloc[:,5]) > 1.0/fc) & (df.iloc[:,4].div(df.iloc[:,5]) < fc)\n",
    "    inds = [ind_up, ind_down, ind_no]\n",
    "    # the extracted binning file \n",
    "    scalefile = '{}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl)\n",
    "    df_scale = pd.read_csv(scalefile, sep='\\t', header=2)\n",
    "    # remove the first colname, which denotes how many peaks\n",
    "    colnames = df_scale.columns.values[1:]\n",
    "    df_scale = df_scale.iloc[:, :-1]\n",
    "    df_scale.columns = colnames\n",
    "    \n",
    "    for ind, ext in zip(inds, exts):\n",
    "        print(ext + '***\\n')\n",
    "        df_tmp = df[ind].copy()\n",
    "        treat_id = [\n",
    "            i for i, ele in enumerate(df_tmp.columns) if treat in ele\n",
    "        ][0]\n",
    "        df_tmp.sort_values(\n",
    "            by=df_tmp.columns[treat_id], inplace=True)  #4: treat\n",
    "        #3. split the df_tmp into three groups for treat and ctrl and delta\n",
    "        inds = df_tmp.index\n",
    "        #3.1 treat: # add 1\n",
    "        treat_id = [i for i, ele in enumerate(colnames) if treat in ele]\n",
    "        df_treat = df_scale.iloc[inds, treat_id]\n",
    "        df_treat.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, treat),\n",
    "            index=False)\n",
    "        #3.2 ctrl:\n",
    "        ctrl_id = [i for i, ele in enumerate(colnames) if ctrl in ele]\n",
    "        df_ctrl = df_scale.iloc[inds, ctrl_id]\n",
    "        df_ctrl.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, ctrl),\n",
    "            index=False)\n",
    "        #3.3 delta verified\n",
    "        df_delta = pd.DataFrame(df_treat.values - df_ctrl.values)\n",
    "        df_delta.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, 'delta'),\n",
    "            index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 116540\r\n",
      "drwxr-xr-x 10 xc3 lilab     4096 Jul 27 22:04 ..\r\n",
      "-rw-r--r--  1 xc3 lilab  2814286 Jul 27 22:03 293_Y78A_ENL.nodiff.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   966632 Jul 27 22:03 293_Y78A_ENL.nodiff.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   961932 Jul 27 22:03 293_Y78A_ENL.nodiff.heatmap.Y78A.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  6636166 Jul 27 22:03 293_Y78A_ENL.lower.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  2331563 Jul 27 22:03 293_Y78A_ENL.lower.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  2296773 Jul 27 22:03 293_Y78A_ENL.lower.heatmap.Y78A.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   253987 Jul 27 22:03 293_Y78A_ENL.upper.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab    92366 Jul 27 22:03 293_Y78A_ENL.upper.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab    92978 Jul 27 22:03 293_Y78A_ENL.upper.heatmap.Y78A.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  5834277 Jul 27 22:03 293_T3_ENL.nodiff.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  2017708 Jul 27 22:03 293_T3_ENL.nodiff.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  2017992 Jul 27 22:03 293_T3_ENL.nodiff.heatmap.T3.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   261869 Jul 27 22:03 293_T3_ENL.lower.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab    95755 Jul 27 22:03 293_T3_ENL.lower.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab    94593 Jul 27 22:03 293_T3_ENL.lower.heatmap.T3.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  9982618 Jul 27 22:03 293_T3_ENL.upper.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  3516780 Jul 27 22:03 293_T3_ENL.upper.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  3543499 Jul 27 22:03 293_T3_ENL.upper.heatmap.T3.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  7180892 Jul 27 22:03 293_T2_ENL.nodiff.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  2482490 Jul 27 22:03 293_T2_ENL.nodiff.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  2476969 Jul 27 22:03 293_T2_ENL.nodiff.heatmap.T2.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   714145 Jul 27 22:03 293_T2_ENL.lower.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   253348 Jul 27 22:03 293_T2_ENL.lower.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   250153 Jul 27 22:03 293_T2_ENL.lower.heatmap.T2.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  6103186 Jul 27 22:03 293_T2_ENL.upper.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  2144114 Jul 27 22:03 293_T2_ENL.upper.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  2155940 Jul 27 22:03 293_T2_ENL.upper.heatmap.T2.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  4671445 Jul 27 22:03 293_T1_ENL.nodiff.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  1614746 Jul 27 22:03 293_T1_ENL.nodiff.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  1608836 Jul 27 22:03 293_T1_ENL.nodiff.heatmap.T1.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  4333778 Jul 27 22:03 293_T1_ENL.lower.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  1515460 Jul 27 22:03 293_T1_ENL.lower.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  1495050 Jul 27 22:03 293_T1_ENL.lower.heatmap.T1.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  1105793 Jul 27 22:03 293_T1_ENL.upper.heatmap.delta.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   395334 Jul 27 22:03 293_T1_ENL.upper.heatmap.ENL.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   401821 Jul 27 22:03 293_T1_ENL.upper.heatmap.T1.txt\r\n",
      "drwxr-xr-x  2 xc3 lilab     8192 Jul 27 16:25 .\r\n",
      "-rw-r--r--  1 xc3 lilab   205512 Jul 27 16:13 293_Y78A_ENL.average.nodiff.txt\r\n",
      "-rw-r--r--  1 xc3 lilab    19034 Jul 27 16:13 293_Y78A_ENL.average.lower.txt\r\n",
      "-rw-r--r--  1 xc3 lilab       73 Jul 27 16:13 293_Y78A_ENL.average.upper.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   364625 Jul 27 16:13 293_T3_ENL.average.nodiff.txt\r\n",
      "-rw-r--r--  1 xc3 lilab      286 Jul 27 16:13 293_T3_ENL.average.lower.txt\r\n",
      "-rw-r--r--  1 xc3 lilab    13998 Jul 27 16:13 293_T3_ENL.average.upper.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   322040 Jul 27 16:13 293_T2_ENL.average.nodiff.txt\r\n",
      "-rw-r--r--  1 xc3 lilab      472 Jul 27 16:13 293_T2_ENL.average.lower.txt\r\n",
      "-rw-r--r--  1 xc3 lilab     4787 Jul 27 16:13 293_T2_ENL.average.upper.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   225662 Jul 27 16:13 293_T1_ENL.average.nodiff.txt\r\n",
      "-rw-r--r--  1 xc3 lilab     5428 Jul 27 16:13 293_T1_ENL.average.lower.txt\r\n",
      "-rw-r--r--  1 xc3 lilab     2857 Jul 27 16:13 293_T1_ENL.average.upper.txt\r\n",
      "-rw-r--r--  1 xc3 lilab  6222767 Jul 27 15:54 293_Y78A_ENL.scale.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   117450 Jul 27 15:54 Y78A.bed\r\n",
      "-rw-r--r--  1 xc3 lilab 10385382 Jul 27 15:54 293_T3_ENL.scale.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   196913 Jul 27 15:53 T3.bed\r\n",
      "-rw-r--r--  1 xc3 lilab  8988771 Jul 27 15:53 293_T2_ENL.scale.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   170209 Jul 27 15:52 T2.bed\r\n",
      "-rw-r--r--  1 xc3 lilab  6487634 Jul 27 15:52 293_T1_ENL.scale.txt\r\n",
      "-rw-r--r--  1 xc3 lilab   122298 Jul 27 15:51 T1.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./res_delta_heatmap/ -alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative plotting the delta heatmap using the previous generated signal to rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr\tstart\tend\twidth\t293_F_Y78A_treat\t293_F_ENL_treat\t293_ctrl\twithin_genebody\tnearest_TSS\tdistance\tlogFC\tPValue\n",
      "chr1\t858702\t861593\t2891\t14.835005188516085\t23.870632998962297\t3.969906606710482\tSAMD11\tSAMD11,LOC100130417\t473,-3630\t-0.6859999999999999\t0.552\n",
      "chr1\t870327\t871455\t1128\t7.6436170212765955\t12.20035460992908\t3.0585106382978724\tSAMD11\tnone\tnone\t-0.675\t0.5720000000000001\n",
      "chr1\t875037\t878559\t3522\t12.062464508801815\t15.90005678591709\t3.0011357183418514\tSAMD11\tnone\tnone\t-0.39899999999999997\t0.915\n",
      "chr1\t901715\t902881\t1166\t9.704116638078904\t10.452830188679245\t2.834476843910806\tPLEKHN1\tPLEKHN1\t-161\t-0.107\t0.415\n",
      "chr1\t932422\t936620\t4198\t13.082896617436873\t20.179132920438303\t3.564078132444022\tHES4\tHES4\t-1068\t-0.625\t0.6559999999999999\n",
      "chr1\t936657\t937855\t1198\t11.450751252086814\t10.560934891485811\t3.6176961602671116\tnone\tHES4\t-1105\t0.11699999999999999\t0.175\n",
      "chr1\t955250\t956213\t963\t8.401869158878505\t11.490134994807892\t3.273104880581516\tAGRN\tAGRN\t-252\t-0.452\t0.982\n",
      "chr1\t1709153\t1710245\t1092\t8.689560439560442\t12.862637362637365\t3.861721611721612\tNADK\tNADK\t52\t-0.5660000000000001\t0.764\n",
      "chr1\t1821251\t1822881\t1630\t12.228834355828221\t17.430674846625767\t3.4957055214723924\tGNB1\tGNB1\t-325\t-0.511\t0.867\n",
      "3573 ./res_avg_signal/293_Y78A_WT.merge.sig.anno.pval.txt\n",
      "3575 ./res_delta_heatmap/293_Y78A_ENL.scale.txt\n"
     ]
    }
   ],
   "source": [
    "!head $sigfile\n",
    "!wc -l $sigfile\n",
    "scalefile = '{}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl)\n",
    "!wc -l $scalefile\n",
    "df_scale = pd.read_csv(scalefile, sep='\\t', header=2)\n",
    "colnames = df_scale.columns.values[1:]\n",
    "df_scale = df_scale.iloc[:, :-1]\n",
    "df_scale.columns = colnames\n",
    "df_tmp = df[ind_up]\n",
    "treat_id = [\n",
    "    i for i, ele in enumerate(df_tmp.columns) if treat in ele\n",
    "][0]\n",
    "df_tmp.sort_values(\n",
    "    by=df_tmp.columns[treat_id], inplace=True)  #4: treat\n",
    "#3. split the df_tmp into three groups for treat and ctrl and delta\n",
    "inds = df_tmp.index\n",
    "#3.1 treat: # add 1\n",
    "treat_id = [i for i, ele in enumerate(colnames) if treat in ele]\n",
    "df_treat = df.iloc[inds, treat_id]\n",
    "df_treat.to_csv(\n",
    "    '{}_{}_{}.{}.heatmap.{}.txt'.format(heatpath + exp, treat,\n",
    "                                        ctrl, ext, treat),\n",
    "    index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess on 293_T1_ENL.scale.txt\n",
      "preprocess on 293_T2_ENL.scale.txt\n",
      "preprocess on 293_T3_ENL.scale.txt\n",
      "preprocess on 293_Y78A_ENL.scale.txt\n"
     ]
    }
   ],
   "source": [
    "for treat in treats:\n",
    "    #1. read the scale file which stores all the bins' signal\n",
    "    count_file = '{}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl)\n",
    "    df = pd.read_csv(count_file, sep='\\t', header=2)\n",
    "    # remove the first colname, which denotes how many peaks\n",
    "    colnames = df.columns.values[1:]\n",
    "    df = df.iloc[:, :-1]\n",
    "    df.columns = colnames\n",
    "    #2. reshape df into 3 groups with increasing order\n",
    "    # *.scale.txt: data for heatmap\n",
    "    # *.average.upper.txt: average value for scale and used for sorting\n",
    "    print('preprocess on {}_{}_{}.scale.txt'.format(exp, treat, ctrl))\n",
    "    exts = ['upper', 'lower', 'nodiff']\n",
    "    for ext in exts:\n",
    "        # index_col: use the previous columns info for the reads counts in df file\n",
    "        df_tmp = pd.read_csv(\n",
    "            '{}_{}_{}.average.{}.txt'.format(outpath+exp, treat, ctrl, ext),\n",
    "            sep='\\t',\n",
    "            index_col=0)\n",
    "        treat_id = [\n",
    "            i for i, ele in enumerate(df_tmp.columns) if treat in ele\n",
    "        ][0]\n",
    "        df_tmp.sort_values(\n",
    "            by=df_tmp.columns[treat_id], inplace=True)  #4: treat\n",
    "        #3. split the df_tmp into three groups for treat and ctrl and delta\n",
    "        inds = df_tmp.index\n",
    "        #3.1 treat: # add 1\n",
    "        treat_id = [i for i, ele in enumerate(colnames) if treat in ele]\n",
    "        df_treat = df.iloc[inds, treat_id]\n",
    "        df_treat.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, treat),\n",
    "            index=False)\n",
    "        #3.2 ctrl:\n",
    "        ctrl_id = [i for i, ele in enumerate(colnames) if ctrl in ele]\n",
    "        df_ctrl = df.iloc[inds, ctrl_id]\n",
    "        df_ctrl.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, ctrl),\n",
    "            index=False)\n",
    "        #3.3 delta verified\n",
    "        df_delta = pd.DataFrame(df_treat.values - df_ctrl.values)\n",
    "        df_delta.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, 'delta'),\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4, it is actually the big heatmap including all peaks called in WT, T1, T2, T3. This is to show that overall the wild type ENL and mutants bind to the same locus. It is similar to the old file I attached here “All in 293.tss.pdf”, but we need it to be peak centered, plus/minus 5 kb region. No cutoff setting applies here, any peaks called in one of the four samples (WT, T1, T2 and T3) should be included here. I think you probably need to merge peaks for this heatmap? And just plot Y78A for the same regions and put at the end, no need to include Y78A when merging peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> merge all the peaks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge a list of the bed files\n",
    "# depeand on the bedtools\n",
    "def merge_beds(bed_files, out_name, header=True):\n",
    "    \"\"\"\n",
    "    bed_files: a list of bed files to be merged\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for bed_file in bed_files:\n",
    "        with open(bed_file, 'r') as f:\n",
    "            lines.extend(f.readlines()[1:] if header else f.readlines())\n",
    "    # merge the two beds together        \n",
    "    with open('tmp.bed','w') as f:\n",
    "        f.writelines(lines)\n",
    "    \n",
    "    # sort the files\n",
    "    command = \"sort -k1,1 -k2,2n tmp.bed > tmp.sorted.bed\"\n",
    "    print(f'execute {command}')\n",
    "    os.system(command)\n",
    "    \n",
    "    # merge the files\n",
    "    command = f\"bedtools merge -i tmp.sorted.bed -d 1 > {out_name}\"\n",
    "    print(f'execute {command}')\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_union\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_union/')\n",
    "!pwd\n",
    "peakpath = '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.bed']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peaksbed = glob.glob(peakpath + '293_F_*.nsp_peaks.bed')\n",
    "peaksbed.sort()\n",
    "peaksbed = peaksbed[:-1]\n",
    "peaksbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed', '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.bed', '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.bed', '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.bed']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'merge_beds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0e11cd4fc671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeaksbed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'293_treat_WT.union.merge.bed'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmerge_beds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeaksbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'merge_beds' is not defined"
     ]
    }
   ],
   "source": [
    "print(peaksbed)\n",
    "out_name = f'293_treat_WT.union.merge.bed'\n",
    "merge_beds(peaksbed, out_name=out_name, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-74a80572ca86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbwfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbwfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'TsWT'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprofile_bed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'~/software/deeptools/bin/computeMatrix reference-point --referencePoint center -S {} -R {} --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o {}.Ts.ENL.center.gz -p 8 --sortUsingSamples 1 --outFileSortedRegions {}.sorted.bed'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbwfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_bed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_name' is not defined"
     ]
    }
   ],
   "source": [
    "# computing the tss signal\n",
    "bwpath = '/home/xc3/output/ENL2/ChIP/bw_nsp/'\n",
    "exp = '293'\n",
    "bwfiles = glob.glob(bwpath+exp+'*.bw')\n",
    "bwfiles.sort()\n",
    "bwfiles = bwfiles[:5]\n",
    "name = 'TsWT'\n",
    "profile_bed = out_name\n",
    "line = '~/software/deeptools/bin/computeMatrix reference-point --referencePoint center -S {} -R {} --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o {}.Ts.ENL.center.gz -p 8 --sortUsingSamples 1 --outFileSortedRegions {}.sorted.bed'.format(' '.join(bwfiles), profile_bed, '{}'.format(name), name)\n",
    "print(line)\n",
    "os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_delta_heatmap.py\t\t\t       res_delta_heatmap\r\n",
      "12.auto_piechart.py\t\t\t       res_heatmap\r\n",
      "5.auto_macs.py\t\t\t\t       res_heatmap_coup_peaks\r\n",
      "6.auto_wig2bw.py\t\t\t       res_heatmap_union\r\n",
      "Co-up_heatmap_venn_peaks_motif_analysis.ipynb  res_motif\r\n",
      "Re_do_with_lambda_macs.ipynb\t\t       res_piecharts\r\n",
      "de_pval_counts.sh\t\t\t       res_venn_diagram\r\n",
      "do_delta_heatmap.ipynb\t\t\t       scripts_macs\r\n",
      "res_avg_signal\t\t\t\t       test.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotHeatmap --sortUsingSamples 1 -m TsWT.Ts.ENL.center.gz  -out TsWT.center.union.pdf --outFileNameMatrix TsWT --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the heatmap for the union of the beds\n",
    "line = 'plotHeatmap --sortUsingSamples 1 -m TsWT.Ts.ENL.center.gz  -out {}.center.union.pdf --outFileNameMatrix {} --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center'.format(name, name, name+'.heatmap.center.union.mat')\n",
    "print(line)\n",
    "os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generated the heatmap associated excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_deeptools_gz_to_df(file_name):\n",
    "    \"\"\"\n",
    "    file_name: the deeptools computeMatrix output matrix gz file\n",
    "    caculate the avg signal per sample across all the bins\n",
    "    \"\"\"\n",
    "    with gzip.open(file_name, 'rt', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    line = lines[0]\n",
    "    a = line.split('@')[-1].split('\\\\')[0]\n",
    "    a = re.sub('true', 'True', a)\n",
    "    a = re.sub('false', 'False', a)\n",
    "    a = re.sub('null', 'False', a)    \n",
    "    info = eval(a)\n",
    "    with open(f'{file_name}.txt', 'w') as f:\n",
    "        f.writelines(lines[1:])\n",
    "\n",
    "    df = pd.read_csv(f'{file_name}.txt', sep='\\t', header=None) \n",
    "    for i, sample in enumerate(info['sample_labels']):\n",
    "        start = info['sample_boundaries'][i] + 6\n",
    "        end = info['sample_boundaries'][i+1] + 6    \n",
    "        df[sample] = df.iloc[:, start:end].mean(axis=1)\n",
    "\n",
    "    df.sort_values(by=[info['sample_labels'][0]], inplace=True, ascending=False)     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_deeptools_gz_to_df(file_name = f'TsWT.Ts.ENL.center.gz')\n",
    "df.iloc[:, [0,1,2,-5,-4,-3,-2,-1]].to_csv('TsWT.Ts.ENL.center.sig.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>293_F_ENL_treat.nsp</th>\n",
       "      <th>293_F_T1_treat.nsp</th>\n",
       "      <th>293_F_T2_treat.nsp</th>\n",
       "      <th>293_F_T3_treat.nsp</th>\n",
       "      <th>293_F_Y78A_treat.nsp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>chr15</td>\n",
       "      <td>96872571</td>\n",
       "      <td>96885658</td>\n",
       "      <td>chr15:96872571-96885658</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>47.40</td>\n",
       "      <td>63.88</td>\n",
       "      <td>58.30</td>\n",
       "      <td>50.28</td>\n",
       "      <td>...</td>\n",
       "      <td>6.62</td>\n",
       "      <td>5.72</td>\n",
       "      <td>6.60</td>\n",
       "      <td>10.14</td>\n",
       "      <td>12.82</td>\n",
       "      <td>31.1782</td>\n",
       "      <td>56.9856</td>\n",
       "      <td>40.1530</td>\n",
       "      <td>47.2304</td>\n",
       "      <td>13.7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>chr6</td>\n",
       "      <td>10407053</td>\n",
       "      <td>10416455</td>\n",
       "      <td>chr6:10407053-10416455</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>6.18</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.06</td>\n",
       "      <td>8.06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.02</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.18</td>\n",
       "      <td>28.3782</td>\n",
       "      <td>31.8884</td>\n",
       "      <td>35.4256</td>\n",
       "      <td>39.2450</td>\n",
       "      <td>12.6170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>chr1</td>\n",
       "      <td>234739252</td>\n",
       "      <td>234749620</td>\n",
       "      <td>chr1:234739252-234749620</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>11.18</td>\n",
       "      <td>14.26</td>\n",
       "      <td>17.86</td>\n",
       "      <td>21.44</td>\n",
       "      <td>...</td>\n",
       "      <td>6.12</td>\n",
       "      <td>8.06</td>\n",
       "      <td>6.74</td>\n",
       "      <td>7.84</td>\n",
       "      <td>10.64</td>\n",
       "      <td>27.7360</td>\n",
       "      <td>22.9514</td>\n",
       "      <td>29.4218</td>\n",
       "      <td>32.7884</td>\n",
       "      <td>16.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>chr7</td>\n",
       "      <td>5457629</td>\n",
       "      <td>5470124</td>\n",
       "      <td>chr7:5457629-5470124</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>21.42</td>\n",
       "      <td>22.80</td>\n",
       "      <td>21.92</td>\n",
       "      <td>22.94</td>\n",
       "      <td>...</td>\n",
       "      <td>7.32</td>\n",
       "      <td>7.22</td>\n",
       "      <td>4.70</td>\n",
       "      <td>6.98</td>\n",
       "      <td>9.32</td>\n",
       "      <td>27.1836</td>\n",
       "      <td>128.0244</td>\n",
       "      <td>63.5452</td>\n",
       "      <td>89.7456</td>\n",
       "      <td>13.3876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>chr6</td>\n",
       "      <td>21593412</td>\n",
       "      <td>21599811</td>\n",
       "      <td>chr6:21593412-21599811</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.99</td>\n",
       "      <td>4.02</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>9.30</td>\n",
       "      <td>6.80</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.69</td>\n",
       "      <td>7.07</td>\n",
       "      <td>27.0541</td>\n",
       "      <td>29.5071</td>\n",
       "      <td>33.8500</td>\n",
       "      <td>38.8271</td>\n",
       "      <td>13.7740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2                         3  4  5      6  \\\n",
       "1959  chr15   96872571   96885658   chr15:96872571-96885658  .  .  47.40   \n",
       "5075   chr6   10407053   10416455    chr6:10407053-10416455  .  .   6.18   \n",
       "601    chr1  234739252  234749620  chr1:234739252-234749620  .  .  11.18   \n",
       "5536   chr7    5457629    5470124      chr7:5457629-5470124  .  .  21.42   \n",
       "5110   chr6   21593412   21599811    chr6:21593412-21599811  .  .   3.40   \n",
       "\n",
       "          7      8      9          ...            501   502   503    504  \\\n",
       "1959  63.88  58.30  50.28          ...           6.62  5.72  6.60  10.14   \n",
       "5075   9.20   9.06   8.06          ...           7.58  7.18  7.02   3.04   \n",
       "601   14.26  17.86  21.44          ...           6.12  8.06  6.74   7.84   \n",
       "5536  22.80  21.92  22.94          ...           7.32  7.22  4.70   6.98   \n",
       "5110   2.99   4.02   5.32          ...           9.30  6.80  9.12   9.69   \n",
       "\n",
       "        505  293_F_ENL_treat.nsp  293_F_T1_treat.nsp  293_F_T2_treat.nsp  \\\n",
       "1959  12.82              31.1782             56.9856             40.1530   \n",
       "5075   3.18              28.3782             31.8884             35.4256   \n",
       "601   10.64              27.7360             22.9514             29.4218   \n",
       "5536   9.32              27.1836            128.0244             63.5452   \n",
       "5110   7.07              27.0541             29.5071             33.8500   \n",
       "\n",
       "      293_F_T3_treat.nsp  293_F_Y78A_treat.nsp  \n",
       "1959             47.2304               13.7206  \n",
       "5075             39.2450               12.6170  \n",
       "601              32.7884               16.0578  \n",
       "5536             89.7456               13.3876  \n",
       "5110             38.8271               13.7740  \n",
       "\n",
       "[5 rows x 511 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the pie charts on the local lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTW, have you generated pie charts for this batch of new peak lists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_piecharts\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_piecharts/')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.bed']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peaksbed = glob.glob(peakpath + '293_F_*.nsp_peaks.bed')\n",
    "peaksbed.sort()\n",
    "peaksbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annoate_bed_to_gene(infile, outfile, cutoff=5000):\n",
    "    ref, tss_set = {}, set()\n",
    "    reffile = '/mount/weili3/xc3/genomes/hg19.refGene.txt'\n",
    "    for line in open(reffile):\n",
    "        col = line.split('\\t')\n",
    "        name, cr, strand, TSS, TES, symbol = col[1], col[2], col[3], int(col[4]), int(col[5]), col[12]\n",
    "        if strand == '-': TSS, TES = TES, TSS\n",
    "        if cr not in ref: ref[cr] = []\n",
    "        if (cr,TSS,strand) not in tss_set:\n",
    "            ref[cr].append((name,symbol,strand,TSS,TES))\n",
    "            tss_set.add((cr,TSS,strand))\n",
    "    for cr in ref: ref[cr].append(('none','none','none',0,0))\n",
    "    \n",
    "    # annotate the file\n",
    "    text = open(infile).readlines()\n",
    "    fout = open(outfile, 'w')\n",
    "    print('processing on {}\\n will output {}\\n'.format(infile,outfile))\n",
    "    for line in text:\n",
    "        col = line.split('\\t')\n",
    "        try: cr, start, end = col[0], int(col[1]), int(col[2])\n",
    "        except: \n",
    "            fout.write(line[:-1]+'\\twithin_genebody\\tnearest_TSS\\tdistance\\n')\n",
    "            continue\n",
    "        if cr not in ref: continue\n",
    "        peak = (start + end) / 2\n",
    "        genes, genebody, genes0, genebody0 = [], [], [], []\n",
    "        for name, symbol, strand, TSS, TES in ref[cr]:\n",
    "            if strand == '+':\n",
    "                dist = end - TSS\n",
    "                if abs(start-TSS)<abs(dist):dist=start-TSS\n",
    "\n",
    "            elif strand == '-':\n",
    "                dist = TSS - end\n",
    "                if abs(TSS - start)<abs(dist):dist=TSS - start\n",
    "\n",
    "            elif strand != 'none': raise ValueError\n",
    "            if abs(dist) <= cutoff: genes.append((abs(dist),symbol,dist)) \n",
    "            if (start - TSS) * (start - TES) <= 0: genebody.append((abs(dist),symbol,dist))\n",
    "            elif (end - TSS) * (end - TES) <= 0: genebody.append((abs(dist),symbol,dist))\n",
    "            elif (start - TSS) * (end - TES) <=0: genebody.append((abs(dist),symbol,dist))\n",
    "        genes, genebody = sorted(genes), sorted(genebody)\n",
    "        for g in sorted(genes):\n",
    "            if g[1] not in [x[1] for x in genes0]: genes0.append(g)\n",
    "        for g in sorted(genebody):\n",
    "            if g[1] not in [x[1] for x in genebody0]: genebody0.append(g)\n",
    "        if any(genes0):\n",
    "            symbols = ','.join([x[1] for x in genes0])\n",
    "            dists = ','.join(['%d' % x[2] for x in sorted(genes0)])\n",
    "        else: symbols, dists = 'none', 'none'\n",
    "        if any(genebody): body = ','.join([x[1] for x in genebody0])\n",
    "        else: body = 'none'\n",
    "        fout.write(line[:-1] + '\\t%s\\t%s\\t%s\\n' % (body,symbols,dists))\n",
    "    fout.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.anno.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.anno.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.anno.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.anno.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.anno.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for infile in peaksbed:\n",
    "    outfile = infile.split('.bed')[0] + '.anno.txt'\n",
    "    annoate_bed_to_gene(infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.anno.txt',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.anno.txt',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.anno.txt',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.anno.txt',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.anno.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(peakpath + '*.anno.txt')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ~/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.anno.txt 293_F_Y78A.pie.pdf\n",
      "python ~/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.anno.txt 293_F_T2.pie.pdf\n",
      "python ~/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.anno.txt 293_F_ENL.pie.pdf\n",
      "python ~/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.anno.txt 293_F_T1.pie.pdf\n",
      "python ~/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.anno.txt 293_F_T3.pie.pdf\n"
     ]
    }
   ],
   "source": [
    "names = [ifile.split('/')[-1].split('.')[0] for ifile in files]\n",
    "for i in range(len(files)):\n",
    "    file2plot = files[i]\n",
    "    outfile = '{}.pie.pdf'.format(names[i])\n",
    "    line = 'python ~/software/plot_piechart.py {} {}'.format(file2plot, outfile)\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## piechart for 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.anno.3k.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.anno.3k.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.anno.3k.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.anno.3k.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.anno.3k.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for infile in peaksbed:\n",
    "    outfile = infile.split('.bed')[0] + '.anno.3k.txt'\n",
    "    annoate_bed_to_gene(infile, outfile, cutoff=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.anno.3k.txt;/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.anno.3k.txt;/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.anno.3k.txt;/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.anno.3k.txt;/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.anno.3k.txt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infiles = glob.glob('/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/*.nsp_peaks.anno.3k.txt')\n",
    "':'.join(infiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /home/xc3/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.anno.3k.txt ./\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = f\"python /home/xc3/software/plot_piechart.py \" + infiles[0] + \" ./\"\n",
    "print(line)\n",
    "os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count the peaks number for piecharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3298 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.anno.1k.txt\n",
      "2373 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T1.nsp_peaks.anno.1k.txt\n",
      "4870 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T2.nsp_peaks.anno.1k.txt\n",
      "5827 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_T3.nsp_peaks.anno.1k.txt\n",
      "1880 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_Y78A.nsp_peaks.anno.1k.txt\n"
     ]
    }
   ],
   "source": [
    "for infile in infiles:\n",
    "#     print(infile)\n",
    "    !wc -l $infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use the anaconda2 envrionment because it has rpy installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
