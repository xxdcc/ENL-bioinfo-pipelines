{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ./3.delta_heatmap_piecharts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3 “the delta heatmap”, it is not only for peaks with more than 1.2-fold changes. Basically you will directly use the **pair-wise comparison signal files you sent to me on July 7th** to generate the delta heatmap, they are named as “**293_Ts_WT.merge.sig.anno.pval**”. Based on that table, you use FC1.2 as cutoff to group peaks into Up, No change, and Down subgroups. Just a reminder, since now we have already used local lamda and input to help with the peak calling, no need to compare to input signal to remove non-specific peaks any more. Then plot them for **peak centered 5 kb** plus/minus regions, similar to the delta heatmap you generated earlier (one example attached here). For the delta map part, use the color scheme Liling suggested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use the 293_Ts_WT.merge.sig.anno.pval in ./res_avg_sig\n",
    "* split the files into three groups **Note** the previous generated group (293.sig.anno) is it the same as the computeMatrix?\n",
    "* computeMatrix use the \"\\t\" seperated bed file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate the delta heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "treats = ['T1', 'T2', 'T3', 'Y78A']\n",
    "ctrl = 'ENL'\n",
    "# sigpath: store the previous generated merged peaks signal for T and wt\n",
    "sigpath = './2.Re_do_with_lambda_macs/' \n",
    "outpath = './3.delta_heatmap_piecharts/'\n",
    "bwpath = '/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/'\n",
    "exp = 'HK2'\n",
    "treat = treats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> generate the bed file and use computeMatrix to generate the bin signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie\n",
      "chr\tstart\tend\twidth\tHK2_F_T1_treat\tHK2_F_ENL_treat\tHK2_ctrl\twithin_genebody\tnearest_TSS\tdistance\tlogFC\tPValue\n",
      "chr1\t804921\t805827\t906.0\t10.561810154525388\t11.479028697571746\t2.8454746136865343\tFAM41C\tnone\tnone\t-0.12\t0.978\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "sigfile = f'{sigpath}{exp}_{treat}_WT.merge.sig.anno.pval.txt'\n",
    "!head $sigfile -n2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the previous bigWig Generated signal to rank the split the peaks into three groups: upper, lower, nodiff\n",
    "Then, use this peak to extract the signal from bw using deeptools computeMatrix\n",
    "Finally, use the matrix to do the heatmap plot\n",
    "\n",
    "Bin size: set from 50 to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR > 1) print $1, $2, $3,NR-2,\".\", \"+\"}' ./2.Re_do_with_lambda_macs/HK2_T1_WT.merge.sig.anno.pval.txt > ./3.delta_heatmap_piecharts/T1.bed\n",
      "****\n",
      "computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 100 --missingDataAsZero -R ./3.delta_heatmap_piecharts/T1.bed -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T1_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw  --skipZeros -o ./3.delta_heatmap_piecharts/HK2_T1_ENL.scale.gz --outFileNameMatrix ./3.delta_heatmap_piecharts/HK2_T1_ENL.scale.txt \n",
      "\n",
      "\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR > 1) print $1, $2, $3,NR-2,\".\", \"+\"}' ./2.Re_do_with_lambda_macs/HK2_T2_WT.merge.sig.anno.pval.txt > ./3.delta_heatmap_piecharts/T2.bed\n",
      "****\n",
      "computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 100 --missingDataAsZero -R ./3.delta_heatmap_piecharts/T2.bed -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T2_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw  --skipZeros -o ./3.delta_heatmap_piecharts/HK2_T2_ENL.scale.gz --outFileNameMatrix ./3.delta_heatmap_piecharts/HK2_T2_ENL.scale.txt \n",
      "\n",
      "\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR > 1) print $1, $2, $3,NR-2,\".\", \"+\"}' ./2.Re_do_with_lambda_macs/HK2_T3_WT.merge.sig.anno.pval.txt > ./3.delta_heatmap_piecharts/T3.bed\n",
      "****\n",
      "computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 100 --missingDataAsZero -R ./3.delta_heatmap_piecharts/T3.bed -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T3_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw  --skipZeros -o ./3.delta_heatmap_piecharts/HK2_T3_ENL.scale.gz --outFileNameMatrix ./3.delta_heatmap_piecharts/HK2_T3_ENL.scale.txt \n",
      "\n",
      "\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR > 1) print $1, $2, $3,NR-2,\".\", \"+\"}' ./2.Re_do_with_lambda_macs/HK2_Y78A_WT.merge.sig.anno.pval.txt > ./3.delta_heatmap_piecharts/Y78A.bed\n",
      "****\n",
      "computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 100 --missingDataAsZero -R ./3.delta_heatmap_piecharts/Y78A.bed -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_Y78A_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw  --skipZeros -o ./3.delta_heatmap_piecharts/HK2_Y78A_ENL.scale.gz --outFileNameMatrix ./3.delta_heatmap_piecharts/HK2_Y78A_ENL.scale.txt \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for treat in treats:\n",
    "    #1. extract the first three columns as the bed file\n",
    "    sigfile = f'{sigpath}{exp}_{treat}_WT.merge.sig.anno.pval.txt'\n",
    "    line = \"awk \\'BEGIN{OFS=\\\"\\\\t\\\"}{if (NR > 1) print $1, $2, $3,NR-2,\\\".\\\", \\\"+\\\"}\\'\" + f' {sigfile} > {outpath}{treat}.bed'\n",
    "    print(line + '\\n****')\n",
    "    os.system(line)\n",
    "    # 2. use the bed file to extract the binning signal (center -5k~5k)\n",
    "    bw_files = [\n",
    "            glob.glob(bwpath + exp + '*' + tmp + '*.bw')[0]\n",
    "            for tmp in [treat, ctrl]\n",
    "    ]\n",
    "    bw_files_format = len(bw_files) * \"{} \"\n",
    "    bw_files_format = bw_files_format.format(*bw_files)\n",
    "    bed_file_format = f'{outpath}{treat}.bed'\n",
    "    command = \"computeMatrix reference-point --referencePoint center -b 5000 -a 5000 -bs 100 --missingDataAsZero -R {0} -S {1} --skipZeros -o {2}.scale.gz --outFileNameMatrix {3}.scale.txt \".format(\n",
    "    bed_file_format, bw_files_format,\n",
    "    outpath + exp + '_' + treat + '_' + ctrl,\n",
    "    outpath + exp + '_' + treat + '_' + ctrl)\n",
    "    print(command + '\\n\\n')\n",
    "    os.system(command)\n",
    "    os.system(\n",
    "        'rm {}.scale.gz'.format(outpath + exp + '_' + treat + '_' + ctrl))   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Split the group according to the previous f'{sigpath}293_{treat}_WT.merge.sig.anno.pval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_line_per_colname_center(colname, colnames, line):\n",
    "    eles = line.split('\\t')\n",
    "    vals = [\n",
    "        eles[id] for id, icolname in enumerate(colnames) if icolname == colname\n",
    "    ]\n",
    "    N = len(vals)\n",
    "    return np.mean(np.array(vals)[N // 4:N // 4 * 3].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use the computeMatrxi to extract the signal and then rank the signal by upper, lower and nodiff\n",
    "Which is Bad (removed in future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess --> ./res_delta_heatmap/293_T1_ENL.scale.txt\n",
      "preprocess --> ./res_delta_heatmap/293_T2_ENL.scale.txt\n",
      "preprocess --> ./res_delta_heatmap/293_T3_ENL.scale.txt\n",
      "preprocess --> ./res_delta_heatmap/293_Y78A_ENL.scale.txt\n"
     ]
    }
   ],
   "source": [
    "for treat in treats:\n",
    "    #5. calculate the averaged signal across all the samples\n",
    "    with open(\n",
    "            '{}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl), 'r') as f:\n",
    "        print('preprocess --> {}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl))\n",
    "        lines = f.readlines()\n",
    "        lines = lines[2:]\n",
    "        colnames = lines[0].rstrip().split('\\t')[1:]\n",
    "        colnames_uniq = np.unique(colnames)\n",
    "        idx = [\n",
    "            i for col in [treat, ctrl]\n",
    "            for i, ele in enumerate(colnames_uniq) if col in ele\n",
    "        ]\n",
    "        colnames_uniq = colnames_uniq[idx]\n",
    "        all_cols = []\n",
    "        for colname_uniq in colnames_uniq:\n",
    "            one_col = []\n",
    "            for line in lines[1:]:\n",
    "                one_col.append(\n",
    "                    average_line_per_colname_center(\n",
    "                        colname_uniq, colnames, line))\n",
    "            all_cols.append(one_col)\n",
    "        df = pd.DataFrame(np.array(all_cols).T, columns=colnames_uniq)\n",
    "        \n",
    "        # combine the peak location and signal\n",
    "        bed_file_format = f'{outpath}{treat}.bed'\n",
    "        df_anno = pd.read_csv(\n",
    "            bed_file_format,\n",
    "            sep='\\t',\n",
    "            header=None,\n",
    "            names=['chr', 'start', 'end', 'gene', 'info', 'strand'])\n",
    "        df_comb = pd.concat([df_anno, df], axis=1)\n",
    "        # remove the peaks which does not have significant signal two fold more than the ctrl\n",
    "        # df_sub = df_comb[(df_comb.iloc[:,3] + df_comb.iloc[:,4]) / df_comb.iloc[:,5] > 4]\n",
    "        df_sub = df_comb\n",
    "        #6. divide the peaks according to the enrichment into three groups\n",
    "        df_sub_upper = df_sub[\n",
    "            df_sub.iloc[:, -2].values / df_sub.iloc[:, -1].values > 1.5]\n",
    "        df_sub_lower = df_sub[\n",
    "            df_sub.iloc[:, -2].values / df_sub.iloc[:, -1].values < 1 / 1.5]\n",
    "        df_sub_nodiff = df_sub[\n",
    "            (df_sub.iloc[:, -2].values / df_sub.iloc[:, -1].values >= 1 / 1.5)\n",
    "            & (df_sub.iloc[:, -2].values / df_sub.iloc[:, -1].values <= 1.5)]\n",
    "        #7. save the upper lower and nodiff results as tables\n",
    "        df_sub_upper.to_csv(\n",
    "            '{}_{}_{}.average.upper.txt'.format(outpath+exp, treat, ctrl),\n",
    "            index=True,\n",
    "            sep='\\t')\n",
    "        df_sub_lower.to_csv(\n",
    "            '{}_{}_{}.average.lower.txt'.format(outpath+exp, treat, ctrl),\n",
    "            index=True,\n",
    "            sep='\\t')\n",
    "        df_sub_nodiff.to_csv(\n",
    "            '{}_{}_{}.average.nodiff.txt'.format(outpath+exp, treat, ctrl),\n",
    "            index=True,\n",
    "            sep='\\t')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for treat in treats:\n",
    "    #1. read the scale file which stores all the bins' signal\n",
    "    count_file = '{}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl)\n",
    "    df = pd.read_csv(count_file, sep='\\t', header=2)\n",
    "    # remove the first colname, which denotes how many peaks\n",
    "    colnames = df.columns.values[1:]\n",
    "    df = df.iloc[:, :-1]\n",
    "    df.columns = colnames\n",
    "    #2. reshape df into 3 groups with increasing order\n",
    "    # *.scale.txt: data for heatmap\n",
    "    # *.average.upper.txt: average value for scale and used for sorting\n",
    "    print('preprocess on {}_{}_{}.scale.txt'.format(exp, treat, ctrl))\n",
    "    exts = ['upper', 'lower', 'nodiff']\n",
    "    for ext in exts:\n",
    "        # index_col: use the previous columns info for the reads counts in df file\n",
    "        df_tmp = pd.read_csv(\n",
    "            '{}_{}_{}.average.{}.txt'.format(outpath+exp, treat, ctrl, ext),\n",
    "            sep='\\t',\n",
    "            index_col=0)\n",
    "        treat_id = [\n",
    "            i for i, ele in enumerate(df_tmp.columns) if treat in ele\n",
    "        ][0]\n",
    "        df_tmp.sort_values(\n",
    "            by=df_tmp.columns[treat_id], inplace=True)  #4: treat\n",
    "        #3. split the df_tmp into three groups for treat and ctrl and delta\n",
    "        inds = df_tmp.index\n",
    "        #3.1 treat: # add 1\n",
    "        treat_id = [i for i, ele in enumerate(colnames) if treat in ele]\n",
    "        df_treat = df.iloc[inds, treat_id]\n",
    "        df_treat.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, treat),\n",
    "            index=False)\n",
    "        #3.2 ctrl:\n",
    "        ctrl_id = [i for i, ele in enumerate(colnames) if ctrl in ele]\n",
    "        df_ctrl = df.iloc[inds, ctrl_id]\n",
    "        df_ctrl.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, ctrl),\n",
    "            index=False)\n",
    "        #3.3 delta verified\n",
    "        df_delta = pd.DataFrame(df_treat.values - df_ctrl.values)\n",
    "        df_delta.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, 'delta'),\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative use the average peak signal as the rank list order for the delta heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess on ./2.Re_do_with_lambda_macs/HK2_T1_WT.merge.sig.anno.pval.txt\n",
      "upper***\n",
      "\n",
      "lower***\n",
      "\n",
      "nodiff***\n",
      "\n",
      "preprocess on ./2.Re_do_with_lambda_macs/HK2_T2_WT.merge.sig.anno.pval.txt\n",
      "upper***\n",
      "\n",
      "lower***\n",
      "\n",
      "nodiff***\n",
      "\n",
      "preprocess on ./2.Re_do_with_lambda_macs/HK2_T3_WT.merge.sig.anno.pval.txt\n",
      "upper***\n",
      "\n",
      "lower***\n",
      "\n",
      "nodiff***\n",
      "\n",
      "preprocess on ./2.Re_do_with_lambda_macs/HK2_Y78A_WT.merge.sig.anno.pval.txt\n",
      "upper***\n",
      "\n",
      "lower***\n",
      "\n",
      "nodiff***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc = 1.5\n",
    "for treat in treats:\n",
    "    sigfile = f'{sigpath}{exp}_{treat}_WT.merge.sig.anno.pval.txt'\n",
    "    df = pd.read_csv(sigfile,sep='\\t',header=0)  \n",
    "    print('preprocess on {}'.format(sigfile))\n",
    "    exts = ['upper', 'lower', 'nodiff']\n",
    "    ind_up = df.iloc[:,4].div(df.iloc[:,5]) >= fc\n",
    "    ind_down = df.iloc[:,4].div(df.iloc[:,5]) <= (1.0/fc)\n",
    "    ind_no = (df.iloc[:,4].div(df.iloc[:,5]) > 1.0/fc) & (df.iloc[:,4].div(df.iloc[:,5]) < fc)\n",
    "    inds = [ind_up, ind_down, ind_no]\n",
    "    # the extracted binning file \n",
    "    scalefile = '{}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl)\n",
    "    df_scale = pd.read_csv(scalefile, sep='\\t', header=2)\n",
    "    # remove the first colname, which denotes how many peaks\n",
    "    colnames = df_scale.columns.values[1:]\n",
    "    df_scale = df_scale.iloc[:, :-1]\n",
    "    df_scale.columns = colnames\n",
    "    \n",
    "    for ind, ext in zip(inds, exts):\n",
    "        print(ext + '***\\n')\n",
    "        df_tmp = df[ind].copy()\n",
    "        treat_id = [\n",
    "            i for i, ele in enumerate(df_tmp.columns) if treat in ele\n",
    "        ][0]\n",
    "        df_tmp.sort_values(\n",
    "            by=df_tmp.columns[treat_id], inplace=True)  #4: treat\n",
    "        #3. split the df_tmp into three groups for treat and ctrl and delta\n",
    "        inds = df_tmp.index\n",
    "        #3.1 treat: # add 1\n",
    "        treat_id = [i for i, ele in enumerate(colnames) if treat in ele]\n",
    "        df_treat = df_scale.iloc[inds, treat_id]\n",
    "        df_treat.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, treat),\n",
    "            index=False)\n",
    "        #3.2 ctrl:\n",
    "        ctrl_id = [i for i, ele in enumerate(colnames) if ctrl in ele]\n",
    "        df_ctrl = df_scale.iloc[inds, ctrl_id]\n",
    "        df_ctrl.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, ctrl),\n",
    "            index=False)\n",
    "        #3.3 delta verified\n",
    "        df_delta = pd.DataFrame(df_treat.values - df_ctrl.values)\n",
    "        df_delta.to_csv(\n",
    "            '{}_{}_{}.{}.heatmap.{}.txt'.format(outpath + exp, treat,\n",
    "                                                ctrl, ext, 'delta'),\n",
    "            index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.lower.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.lower.heatmap.T1.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.lower.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.nodiff.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.nodiff.heatmap.T1.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.nodiff.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.upper.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.upper.heatmap.T1.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.upper.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.lower.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.lower.heatmap.T2.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.lower.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.nodiff.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.nodiff.heatmap.T2.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.nodiff.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.upper.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.upper.heatmap.T2.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.upper.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.lower.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.lower.heatmap.T3.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.lower.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.nodiff.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.nodiff.heatmap.T3.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.nodiff.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.upper.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.upper.heatmap.T3.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.upper.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.lower.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.lower.heatmap.Y78A.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.lower.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.nodiff.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.nodiff.heatmap.Y78A.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.nodiff.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.upper.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.upper.heatmap.Y78A.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.upper.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.lower.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.lower.heatmap.T1.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.lower.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.nodiff.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.nodiff.heatmap.T1.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.nodiff.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.upper.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.upper.heatmap.T1.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T1_ENL.upper.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.lower.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.lower.heatmap.T2.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.lower.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.nodiff.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.nodiff.heatmap.T2.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.nodiff.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.upper.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.upper.heatmap.T2.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T2_ENL.upper.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.lower.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.lower.heatmap.T3.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.lower.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.nodiff.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.nodiff.heatmap.T3.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.nodiff.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.upper.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.upper.heatmap.T3.txt\n",
      "./3.delta_heatmap_piecharts/HK2_T3_ENL.upper.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.lower.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.lower.heatmap.Y78A.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.lower.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.nodiff.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.nodiff.heatmap.Y78A.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.nodiff.heatmap.delta.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.upper.heatmap.ENL.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.upper.heatmap.Y78A.txt\n",
      "./3.delta_heatmap_piecharts/HK2_Y78A_ENL.upper.heatmap.delta.txt\n",
      "HK2_delta_1.5.tar\n"
     ]
    }
   ],
   "source": [
    "!ls ./3.delta_heatmap_piecharts/*.heatmap*.txt\n",
    "!tar -cvf HK2_delta_1.5.tar ./3.delta_heatmap_piecharts/*.heatmap*.txt\n",
    "!ls *.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp HK2_delta_1.5.tar /mount/weili2/lilab/xc3/ENL2/ChIP/tmp/HK2_delta_1.5.tar\n",
      "http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/HK2_delta_1.5.tar\n"
     ]
    }
   ],
   "source": [
    "def generate_outer_links(files):\n",
    "    public_url_pre = \"http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/\"\n",
    "    public_url_folder = \"/mount/weili2/lilab/xc3/ENL2/ChIP/tmp/\"\n",
    "    for ifile in files:\n",
    "        file_name = ifile.split('/')[-1]\n",
    "        line = f\"cp {ifile} {public_url_folder}{ifile}\"\n",
    "        print(line)\n",
    "        os.system(line)\n",
    "        print(f'{public_url_pre}{ifile}')\n",
    "        \n",
    "files = glob.glob('*.tar')\n",
    "files\n",
    "generate_outer_linksrate_outer_links(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative plotting the delta heatmap using the previous generated signal to rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr\tstart\tend\twidth\t293_F_Y78A_treat\t293_F_ENL_treat\t293_ctrl\twithin_genebody\tnearest_TSS\tdistance\tlogFC\tPValue\n",
      "chr1\t858702\t861593\t2891\t14.835005188516085\t23.870632998962297\t3.969906606710482\tSAMD11\tSAMD11,LOC100130417\t473,-3630\t-0.6859999999999999\t0.552\n",
      "chr1\t870327\t871455\t1128\t7.6436170212765955\t12.20035460992908\t3.0585106382978724\tSAMD11\tnone\tnone\t-0.675\t0.5720000000000001\n",
      "chr1\t875037\t878559\t3522\t12.062464508801815\t15.90005678591709\t3.0011357183418514\tSAMD11\tnone\tnone\t-0.39899999999999997\t0.915\n",
      "chr1\t901715\t902881\t1166\t9.704116638078904\t10.452830188679245\t2.834476843910806\tPLEKHN1\tPLEKHN1\t-161\t-0.107\t0.415\n",
      "chr1\t932422\t936620\t4198\t13.082896617436873\t20.179132920438303\t3.564078132444022\tHES4\tHES4\t-1068\t-0.625\t0.6559999999999999\n",
      "chr1\t936657\t937855\t1198\t11.450751252086814\t10.560934891485811\t3.6176961602671116\tnone\tHES4\t-1105\t0.11699999999999999\t0.175\n",
      "chr1\t955250\t956213\t963\t8.401869158878505\t11.490134994807892\t3.273104880581516\tAGRN\tAGRN\t-252\t-0.452\t0.982\n",
      "chr1\t1709153\t1710245\t1092\t8.689560439560442\t12.862637362637365\t3.861721611721612\tNADK\tNADK\t52\t-0.5660000000000001\t0.764\n",
      "chr1\t1821251\t1822881\t1630\t12.228834355828221\t17.430674846625767\t3.4957055214723924\tGNB1\tGNB1\t-325\t-0.511\t0.867\n",
      "3573 ./res_avg_signal/293_Y78A_WT.merge.sig.anno.pval.txt\n",
      "3575 ./res_delta_heatmap/293_Y78A_ENL.scale.txt\n"
     ]
    }
   ],
   "source": [
    "!head $sigfile\n",
    "!wc -l $sigfile\n",
    "scalefile = '{}.scale.txt'.format(outpath + exp + '_' + treat + '_' + ctrl)\n",
    "!wc -l $scalefile\n",
    "df_scale = pd.read_csv(scalefile, sep='\\t', header=2)\n",
    "colnames = df_scale.columns.values[1:]\n",
    "df_scale = df_scale.iloc[:, :-1]\n",
    "df_scale.columns = colnames\n",
    "df_tmp = df[ind_up]\n",
    "treat_id = [\n",
    "    i for i, ele in enumerate(df_tmp.columns) if treat in ele\n",
    "][0]\n",
    "df_tmp.sort_values(\n",
    "    by=df_tmp.columns[treat_id], inplace=True)  #4: treat\n",
    "#3. split the df_tmp into three groups for treat and ctrl and delta\n",
    "inds = df_tmp.index\n",
    "#3.1 treat: # add 1\n",
    "treat_id = [i for i, ele in enumerate(colnames) if treat in ele]\n",
    "df_treat = df.iloc[inds, treat_id]\n",
    "df_treat.to_csv(\n",
    "    '{}_{}_{}.{}.heatmap.{}.txt'.format(heatpath + exp, treat,\n",
    "                                        ctrl, ext, treat),\n",
    "    index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4, it is actually the big heatmap including all peaks called in WT, T1, T2, T3. This is to show that overall the wild type ENL and mutants bind to the same locus. It is similar to the old file I attached here “All in 293.tss.pdf”, but we need it to be peak centered, plus/minus 5 kb region. No cutoff setting applies here, any peaks called in one of the four samples (WT, T1, T2 and T3) should be included here. I think you probably need to merge peaks for this heatmap? And just plot Y78A for the same regions and put at the end, no need to include Y78A when merging peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> merge all the peaks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge a list of the bed files\n",
    "# depeand on the bedtools\n",
    "def merge_beds(bed_files, out_name, header=True):\n",
    "    \"\"\"\n",
    "    bed_files: a list of bed files to be merged\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for bed_file in bed_files:\n",
    "        with open(bed_file, 'r') as f:\n",
    "            lines.extend(f.readlines()[1:] if header else f.readlines())\n",
    "    # merge the two beds together        \n",
    "    with open('tmp.bed','w') as f:\n",
    "        f.writelines(lines)\n",
    "    \n",
    "    # sort the files\n",
    "    command = \"sort -k1,1 -k2,2n tmp.bed > tmp.sorted.bed\"\n",
    "    print(f'execute {command}')\n",
    "    os.system(command)\n",
    "    \n",
    "    # merge the files\n",
    "    command = f\"bedtools merge -i tmp.sorted.bed -d 1 > {out_name}\"\n",
    "    print(f'execute {command}')\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Use_first_batch_coup_extract_signal_from_second_batch.ipynb\r\n",
      "2.Re_do_with_lambda_macs\r\n",
      "2.Re_do_with_lambda_macs.ipynb\r\n",
      "3.delta_heatmap_piecharts\r\n",
      "3.do_delta_heatmap_piecharts.ipynb\r\n",
      "3.heatmap_union\r\n",
      "avg_sig_0.txt\r\n",
      "avg_sig_1.txt\r\n",
      "avg_sig_2.txt\r\n",
      "de_pval_counts.sh\r\n",
      "heatmap_union\r\n",
      "res_second_batch_using_first_batch_peak\r\n",
      "testT1WT.bed\r\n",
      "testY78AWT.bed\r\n",
      "tmp.bed\r\n",
      "tmp.sorted.bed\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./3.heatmap_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/3.heatmap_union\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/3.heatmap_union/')\n",
    "!pwd\n",
    "peakpath = '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.bed']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peaksbed = glob.glob(peakpath + 'HK2_F_*.nsp_peaks.bed')\n",
    "peaksbed.sort()\n",
    "peaksbed = peaksbed[:-1]\n",
    "peaksbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.bed', '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.bed', '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.bed', '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.bed']\n",
      "execute sort -k1,1 -k2,2n tmp.bed > tmp.sorted.bed\n",
      "execute bedtools merge -i tmp.sorted.bed -d 1 > HK2_treat_WT.union.merge.bed\n"
     ]
    }
   ],
   "source": [
    "print(peaksbed)\n",
    "out_name = f'HK2_treat_WT.union.merge.bed'\n",
    "merge_beds(peaksbed, out_name=out_name, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T1_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T2_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T3_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_Y78A_treat.nsp.bw -R HK2_treat_WT.union.merge.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o TsWT.Ts.ENL.center.gz -p 8 --sortUsingSamples 1 --outFileSortedRegions TsWT.sorted.bed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the tss signal\n",
    "exp = 'HK2'\n",
    "bwfiles = glob.glob(bwpath+exp+'*.bw')\n",
    "bwfiles.sort()\n",
    "bwfiles = bwfiles[:5]\n",
    "name = 'TsWT'\n",
    "profile_bed = out_name\n",
    "line = 'computeMatrix reference-point --referencePoint center -S {} -R {} --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o {}.Ts.ENL.center.gz -p 8 --sortUsingSamples 1 --outFileSortedRegions {}.sorted.bed'.format(' '.join(bwfiles), profile_bed, '{}'.format(name), name)\n",
    "print(line)\n",
    "os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HK2_treat_WT.union.merge.bed  TsWT.sorted.bed  tmp.sorted.bed\r\n",
      "TsWT.Ts.ENL.center.gz\t      tmp.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotHeatmap --sortUsingSamples 1 -m TsWT.Ts.ENL.center.gz  -out HK2.TsWT.center.union.pdf --outFileNameMatrix TsWT --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the heatmap for the union of the beds\n",
    "line = 'plotHeatmap --sortUsingSamples 1 -m TsWT.Ts.ENL.center.gz  -out HK2.{}.center.union.pdf --outFileNameMatrix {} --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center'.format(name, name, name+'.heatmap.center.union.mat')\n",
    "print(line)\n",
    "os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generated the heatmap associated excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_deeptools_gz_to_df(file_name):\n",
    "    \"\"\"\n",
    "    file_name: the deeptools computeMatrix output matrix gz file\n",
    "    caculate the avg signal per sample across all the bins\n",
    "    \"\"\"\n",
    "    with gzip.open(file_name, 'rt', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    line = lines[0]\n",
    "    a = line.split('@')[-1].split('\\\\')[0]\n",
    "    a = re.sub('true', 'True', a)\n",
    "    a = re.sub('false', 'False', a)\n",
    "    a = re.sub('null', 'False', a)    \n",
    "    info = eval(a)\n",
    "    with open(f'{file_name}.txt', 'w') as f:\n",
    "        f.writelines(lines[1:])\n",
    "\n",
    "    df = pd.read_csv(f'{file_name}.txt', sep='\\t', header=None) \n",
    "    for i, sample in enumerate(info['sample_labels']):\n",
    "        start = info['sample_boundaries'][i] + 6\n",
    "        end = info['sample_boundaries'][i+1] + 6    \n",
    "        df[sample] = df.iloc[:, start:end].mean(axis=1)\n",
    "\n",
    "    df.sort_values(by=[info['sample_labels'][0]], inplace=True, ascending=False)     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_deeptools_gz_to_df(file_name = f'TsWT.Ts.ENL.center.gz')\n",
    "df.iloc[:, [0,1,2,-5,-4,-3,-2,-1]].to_csv('HK2.TsWT.Ts.ENL.center.sig.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>HK2_F_ENL_treat.nsp</th>\n",
       "      <th>HK2_F_T1_treat.nsp</th>\n",
       "      <th>HK2_F_T2_treat.nsp</th>\n",
       "      <th>HK2_F_T3_treat.nsp</th>\n",
       "      <th>HK2_F_Y78A_treat.nsp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8928</th>\n",
       "      <td>chr21</td>\n",
       "      <td>9825287</td>\n",
       "      <td>9828084</td>\n",
       "      <td>chr21:9825287-9828084</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.85</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.55</td>\n",
       "      <td>7.15</td>\n",
       "      <td>72.4015</td>\n",
       "      <td>73.8760</td>\n",
       "      <td>71.9365</td>\n",
       "      <td>75.5500</td>\n",
       "      <td>73.8525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>chr14</td>\n",
       "      <td>62160514</td>\n",
       "      <td>62174448</td>\n",
       "      <td>chr14:62160514-62174448</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>111.75</td>\n",
       "      <td>122.99</td>\n",
       "      <td>109.76</td>\n",
       "      <td>113.44</td>\n",
       "      <td>...</td>\n",
       "      <td>6.61</td>\n",
       "      <td>7.61</td>\n",
       "      <td>13.26</td>\n",
       "      <td>16.40</td>\n",
       "      <td>15.29</td>\n",
       "      <td>48.6380</td>\n",
       "      <td>62.7270</td>\n",
       "      <td>46.0369</td>\n",
       "      <td>73.6199</td>\n",
       "      <td>12.8394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>chr14</td>\n",
       "      <td>69250575</td>\n",
       "      <td>69263613</td>\n",
       "      <td>chr14:69250575-69263613</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>19.84</td>\n",
       "      <td>20.34</td>\n",
       "      <td>17.72</td>\n",
       "      <td>19.26</td>\n",
       "      <td>...</td>\n",
       "      <td>12.60</td>\n",
       "      <td>13.64</td>\n",
       "      <td>11.12</td>\n",
       "      <td>9.40</td>\n",
       "      <td>10.66</td>\n",
       "      <td>43.2216</td>\n",
       "      <td>31.9252</td>\n",
       "      <td>32.7894</td>\n",
       "      <td>53.8662</td>\n",
       "      <td>12.8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12397</th>\n",
       "      <td>chr7</td>\n",
       "      <td>27185065</td>\n",
       "      <td>27221024</td>\n",
       "      <td>chr7:27185065-27221024</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>33.32</td>\n",
       "      <td>43.68</td>\n",
       "      <td>53.78</td>\n",
       "      <td>66.28</td>\n",
       "      <td>...</td>\n",
       "      <td>9.24</td>\n",
       "      <td>10.02</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5.68</td>\n",
       "      <td>13.92</td>\n",
       "      <td>42.5946</td>\n",
       "      <td>125.1380</td>\n",
       "      <td>84.1482</td>\n",
       "      <td>129.1008</td>\n",
       "      <td>11.2298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9801</th>\n",
       "      <td>chr3</td>\n",
       "      <td>101565533</td>\n",
       "      <td>101584291</td>\n",
       "      <td>chr3:101565533-101584291</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>62.66</td>\n",
       "      <td>60.32</td>\n",
       "      <td>49.18</td>\n",
       "      <td>43.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13.28</td>\n",
       "      <td>8.98</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.44</td>\n",
       "      <td>7.60</td>\n",
       "      <td>41.7046</td>\n",
       "      <td>42.0786</td>\n",
       "      <td>28.6024</td>\n",
       "      <td>59.6928</td>\n",
       "      <td>11.2794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2                         3  4  5       6  \\\n",
       "8928   chr21    9825287    9828084     chr21:9825287-9828084  .  .    0.00   \n",
       "4025   chr14   62160514   62174448   chr14:62160514-62174448  .  .  111.75   \n",
       "4073   chr14   69250575   69263613   chr14:69250575-69263613  .  .   19.84   \n",
       "12397   chr7   27185065   27221024    chr7:27185065-27221024  .  .   33.32   \n",
       "9801    chr3  101565533  101584291  chr3:101565533-101584291  .  .   62.66   \n",
       "\n",
       "            7       8       9          ...             501    502    503  \\\n",
       "8928     0.00    0.00    0.00          ...            5.20   4.85   3.20   \n",
       "4025   122.99  109.76  113.44          ...            6.61   7.61  13.26   \n",
       "4073    20.34   17.72   19.26          ...           12.60  13.64  11.12   \n",
       "12397   43.68   53.78   66.28          ...            9.24  10.02   7.32   \n",
       "9801    60.32   49.18   43.00          ...           13.28   8.98   6.36   \n",
       "\n",
       "         504    505  HK2_F_ENL_treat.nsp  HK2_F_T1_treat.nsp  \\\n",
       "8928    2.55   7.15              72.4015             73.8760   \n",
       "4025   16.40  15.29              48.6380             62.7270   \n",
       "4073    9.40  10.66              43.2216             31.9252   \n",
       "12397   5.68  13.92              42.5946            125.1380   \n",
       "9801    6.44   7.60              41.7046             42.0786   \n",
       "\n",
       "       HK2_F_T2_treat.nsp  HK2_F_T3_treat.nsp  HK2_F_Y78A_treat.nsp  \n",
       "8928              71.9365             75.5500               73.8525  \n",
       "4025              46.0369             73.6199               12.8394  \n",
       "4073              32.7894             53.8662               12.8782  \n",
       "12397             84.1482            129.1008               11.2298  \n",
       "9801              28.6024             59.6928               11.2794  \n",
       "\n",
       "[5 rows x 511 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the pie charts on the local lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTW, have you generated pie charts for this batch of new peak lists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/3.delta_heatmap_piecharts\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/3.delta_heatmap_piecharts/')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.bed',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_Y78A.nsp_peaks.bed']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peaksbed = glob.glob(peakpath + f'{exp}_F_*.nsp_peaks.bed')\n",
    "peaksbed.sort()\n",
    "peaksbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annoate_bed_to_gene(infile, outfile, cutoff=5000):\n",
    "    ref, tss_set = {}, set()\n",
    "    reffile = '/mount/weili3/xc3/genomes/hg19.refGene.txt'\n",
    "    for line in open(reffile):\n",
    "        col = line.split('\\t')\n",
    "        name, cr, strand, TSS, TES, symbol = col[1], col[2], col[3], int(col[4]), int(col[5]), col[12]\n",
    "        if strand == '-': TSS, TES = TES, TSS\n",
    "        if cr not in ref: ref[cr] = []\n",
    "        if (cr,TSS,strand) not in tss_set:\n",
    "            ref[cr].append((name,symbol,strand,TSS,TES))\n",
    "            tss_set.add((cr,TSS,strand))\n",
    "    for cr in ref: ref[cr].append(('none','none','none',0,0))\n",
    "    \n",
    "    # annotate the file\n",
    "    text = open(infile).readlines()\n",
    "    fout = open(outfile, 'w')\n",
    "    print('processing on {}\\n will output {}\\n'.format(infile,outfile))\n",
    "    for line in text:\n",
    "        col = line.split('\\t')\n",
    "        try: cr, start, end = col[0], int(col[1]), int(col[2])\n",
    "        except: \n",
    "            fout.write(line[:-1]+'\\twithin_genebody\\tnearest_TSS\\tdistance\\n')\n",
    "            continue\n",
    "        if cr not in ref: continue\n",
    "        peak = (start + end) / 2\n",
    "        genes, genebody, genes0, genebody0 = [], [], [], []\n",
    "        for name, symbol, strand, TSS, TES in ref[cr]:\n",
    "            if strand == '+':\n",
    "                dist = end - TSS\n",
    "                if abs(start-TSS)<abs(dist):dist=start-TSS\n",
    "\n",
    "            elif strand == '-':\n",
    "                dist = TSS - end\n",
    "                if abs(TSS - start)<abs(dist):dist=TSS - start\n",
    "\n",
    "            elif strand != 'none': raise ValueError\n",
    "            if abs(dist) <= cutoff: genes.append((abs(dist),symbol,dist)) \n",
    "            if (start - TSS) * (start - TES) <= 0: genebody.append((abs(dist),symbol,dist))\n",
    "            elif (end - TSS) * (end - TES) <= 0: genebody.append((abs(dist),symbol,dist))\n",
    "            elif (start - TSS) * (end - TES) <=0: genebody.append((abs(dist),symbol,dist))\n",
    "        genes, genebody = sorted(genes), sorted(genebody)\n",
    "        for g in sorted(genes):\n",
    "            if g[1] not in [x[1] for x in genes0]: genes0.append(g)\n",
    "        for g in sorted(genebody):\n",
    "            if g[1] not in [x[1] for x in genebody0]: genebody0.append(g)\n",
    "        if any(genes0):\n",
    "            symbols = ','.join([x[1] for x in genes0])\n",
    "            dists = ','.join(['%d' % x[2] for x in sorted(genes0)])\n",
    "        else: symbols, dists = 'none', 'none'\n",
    "        if any(genebody): body = ','.join([x[1] for x in genebody0])\n",
    "        else: body = 'none'\n",
    "        fout.write(line[:-1] + '\\t%s\\t%s\\t%s\\n' % (body,symbols,dists))\n",
    "    fout.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.3k.anno.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.3k.anno.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.3k.anno.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.3k.anno.txt\n",
      "\n",
      "processing on /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_Y78A.nsp_peaks.bed\n",
      " will output /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_Y78A.nsp_peaks.3k.anno.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for infile in peaksbed:\n",
    "    outfile = infile.split('.bed')[0] + '.3k.anno.txt'\n",
    "    annoate_bed_to_gene(infile, outfile,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.3k.anno.txt',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.3k.anno.txt',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.3k.anno.txt',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.3k.anno.txt',\n",
       " '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_Y78A.nsp_peaks.3k.anno.txt']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(peakpath + f'{exp}*.3k.anno.txt')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ~/xc3/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.3k.anno.txt ./\n",
      "python ~/xc3/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.3k.anno.txt ./\n",
      "python ~/xc3/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.3k.anno.txt ./\n",
      "python ~/xc3/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.3k.anno.txt ./\n",
      "python ~/xc3/software/plot_piechart.py /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_Y78A.nsp_peaks.3k.anno.txt ./\n"
     ]
    }
   ],
   "source": [
    "names = [ifile.split('/')[-1].split('.')[0] for ifile in files]\n",
    "for i in range(len(files)):\n",
    "    file2plot = files[i]\n",
    "    outfile = '{}.pie.pdf'.format(names[i])\n",
    "    line = 'python ~/xc3/software/plot_piechart.py {} {}'.format(file2plot, './')\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count the peaks number for piecharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9911 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.3k.anno.txt\n",
      "7154 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.3k.anno.txt\n",
      "8010 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.3k.anno.txt\n",
      "13710 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.3k.anno.txt\n",
      "4539 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_Y78A.nsp_peaks.3k.anno.txt\n"
     ]
    }
   ],
   "source": [
    "for infile in files:\n",
    "#     print(infile)\n",
    "    !wc -l $infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
