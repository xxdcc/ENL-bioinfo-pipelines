{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hong's job description\n",
    "\n",
    "Attached please find the venn diagrams we generated based on the lists your provided, I also sent you the shared enhanced binding gene lists for both FC>1.2 (333 genes) and FC>1.5 (87 genes). Please generate TSS centered heatmaps for these two list genes respectively. Also include Y78A in these heatmaps. The dark blue color we usually use for Flag ChIP peaks would be good.\n",
    "\n",
    "At the meantime, you can help to generate venn diagram for WT, T1, T2 and T3, and the heatmaps for co-up peaks.\n",
    "\n",
    "For the motif analysis, please analysis the following four groups of genes: (1) 333 genes with FC>1.2 enhanced binding; (2) 87 genes with FC>1.5 enhanced binding; (3) T3 vs.WT FC>1.5 enhanced binding. For this three, please find enriched motifs in TSS +/- 2kb region. And then (4) look for enriched motifs in wild type ENL binding peaks.\n",
    "\n",
    "Comments 2018-8-17\n",
    "Tss will change to the peak center\n",
    "venn diagram for all Ts and ENL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate the venn diagram for peaks for T1 T2 T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ./4.venn_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.venn_diagram\r\n"
     ]
    }
   ],
   "source": [
    "workPath = '/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.venn_diagram/'\n",
    "os.chdir(workPath)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T2.nsp_peaks.bed > HK2_F_T2.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_Y78A.nsp_peaks.bed > HK2_F_Y78A.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T1.nsp_peaks.bed > HK2_F_T1.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_T3.nsp_peaks.bed > HK2_F_T3.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{print $1,$2,$3}' /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/HK2_F_ENL.nsp_peaks.bed > HK2_F_ENL.bed\n"
     ]
    }
   ],
   "source": [
    "exp = 'HK2'\n",
    "bed_path = '/mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/'\n",
    "bedFiles = glob.glob(f'{bed_path}{exp}*nsp_peaks.bed')\n",
    "# extract the first three columns of the bed files\n",
    "for bedFile in bedFiles:\n",
    "    outFile = bedFile.split('/')[-1].split('.')[0]\n",
    "    line = \"awk \\'BEGIN{OFS=\\\"\\\\t\\\"}{print $1,$2,$3}\\'\" + f' {bedFile} > {outFile}.bed'\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ppn = [1, 1]\n",
    "memory = 4\n",
    "wait_time = [20, 00]\n",
    "quene = \"short\"\n",
    "files = glob.glob('*.bed')\n",
    "files.sort()\n",
    "files = files[:-1]\n",
    "names = [ifile.split('/')[-1].split('.')[0] for ifile in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HK2_F_ENL.bed', 'HK2_F_T1.bed', 'HK2_F_T2.bed', 'HK2_F_T3.bed']\n",
      "python /home/jlyu/xc3/software/bed_overlap4.py -v HK2_all.venn.pdf -i HK2_all.venn.bed HK2_F_ENL.bed HK2_F_T1.bed HK2_F_T2.bed HK2_F_T3.bed \n"
     ]
    }
   ],
   "source": [
    "# open the initialization header for pbs and read the contents\n",
    "with open('/home/jlyu/xc3/experiment/initial.pbs','r') as f:\n",
    "    pbs_header = f.readlines()\n",
    "\n",
    "# write each sample a pbs files\n",
    "experiment_name = \"{}.ato\".format('venn_diagram')\n",
    "with open(experiment_name,'w') as f:\n",
    "    pbs_initial = pbs_header[:]\n",
    "    # configuration for the experiments\n",
    "    # pbs_initial[1]::job name\n",
    "    pbs_initial[1] = pbs_initial[1].format('venn')\n",
    "    # pbs_initial[2]::nodes and ppn\n",
    "    pbs_initial[2] = pbs_initial[2].format(*nodes_ppn)\n",
    "    # pbs_initial[4]::memeroy\n",
    "    pbs_initial[4] = pbs_initial[4].format(memory)\n",
    "    # pbs_initial[5]::waiting time\n",
    "    pbs_initial[5] = pbs_initial[5].format(*wait_time)\n",
    "    # pbs_initial[11]::err output\n",
    "    pbs_initial[11] = pbs_initial[11].format('venn')\n",
    "    # pbs_initial[12]::log\n",
    "    pbs_initial[12] = pbs_initial[12].format('venn')\n",
    "    # pbs_initial[14]::quene\n",
    "    pbs_initial[14] = pbs_initial[14].format(quene)\n",
    "    \n",
    "    #write all the configurations into the pbs file\n",
    "    for line in pbs_initial:\n",
    "        f.write(line)\n",
    "    line = f'cd {workPath}'\n",
    "    f.write(line + '\\n')\n",
    "\n",
    "    treat_files = files\n",
    "    print(treat_files)\n",
    "    treat_files_format = '{} ' * len(treat_files)\n",
    "    treat_files_format = treat_files_format.format(*treat_files)\n",
    "    output_venn = '{}_all.venn.pdf'.format(exp)\n",
    "    output_bed = '{}_all.venn.bed'.format(exp)\n",
    "    line = 'python /home/jlyu/xc3/software/bed_overlap4.py -v {} -i {} {}'.format(output_venn, output_bed, treat_files_format)\n",
    "    print(line)\n",
    "    f.write(line + '\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Heatmap for subgroup coup peaks\n",
    "\n",
    "The coup peaks comes from the venn analysis intersection from bedoverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks\r\n"
     ]
    }
   ],
   "source": [
    "workPath = '/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks'\n",
    "os.chdir(workPath)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 extract the 1.2 / 1.5 peaks as bed files then use bedoverlap to get the intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths = [1.2, 1.5]\n",
    "names = ['1_2','1_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2.Ts.ENL.peak.gz\t  HK2.all.1_5.sig.anno.txt\r\n",
      "1_2.Ts.ENL.peak.gz.txt\t  HK2.all.1_5.str.bed\r\n",
      "1_2.heatmap.peak.mat\t  HK2_T1_WT.1_2.bed\r\n",
      "1_5.Ts.ENL.peak.gz\t  HK2_T1_WT.1_5.bed\r\n",
      "1_5.Ts.ENL.peak.gz.txt\t  HK2_T1_WT.merge.counts.anno.pval.txt\r\n",
      "1_5.heatmap.peak.mat\t  HK2_T2_WT.1_2.bed\r\n",
      "293.all.1_2.new.heat.bed  HK2_T2_WT.1_5.bed\r\n",
      "293.all.1_5.new.heat.bed  HK2_T2_WT.merge.counts.anno.pval.txt\r\n",
      "HK2.1_2.peak.pdf\t  HK2_T3_WT.1_2.bed\r\n",
      "HK2.1_2.peak.sig.txt\t  HK2_T3_WT.1_5.bed\r\n",
      "HK2.1_5.peak.pdf\t  HK2_T3_WT.merge.counts.anno.pval.txt\r\n",
      "HK2.1_5.peak.sig.txt\t  PeakMatrix_HK2_F_ENL_co-UP_genes.1_5.gz\r\n",
      "HK2.all.1_2.bed\t\t  PeakMatrix_HK2_F_ENL_co-UP_genes.gz\r\n",
      "HK2.all.1_2.counts.txt\t  PeakMatrix_HK2_F_T1_co-UP_genes.1_5.gz\r\n",
      "HK2.all.1_2.heat.bed\t  PeakMatrix_HK2_F_T1_co-UP_genes.gz\r\n",
      "HK2.all.1_2.new.heat.bed  PeakMatrix_HK2_F_T2_co-UP_genes.1_5.gz\r\n",
      "HK2.all.1_2.sig.anno.txt  PeakMatrix_HK2_F_T2_co-UP_genes.gz\r\n",
      "HK2.all.1_2.str.bed\t  PeakMatrix_HK2_F_T3_co-UP_genes.1_5.gz\r\n",
      "HK2.all.1_5.bed\t\t  PeakMatrix_HK2_F_T3_co-UP_genes.gz\r\n",
      "HK2.all.1_5.counts.txt\t  PeakMatrix_HK2_F_Y78A_co-UP_genes.1_5.gz\r\n",
      "HK2.all.1_5.heat.bed\t  PeakMatrix_HK2_F_Y78A_co-UP_genes.gz\r\n",
      "HK2.all.1_5.new.heat.bed  TsWT.sorted.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 12) --> HK2_T1_WT.merge.counts.anno.pval.txt 1.2\n",
      "HK2_T1_WT.1_2.bed\n",
      "(940, 12) --> HK2_T2_WT.merge.counts.anno.pval.txt 1.2\n",
      "HK2_T2_WT.1_2.bed\n",
      "(9607, 12) --> HK2_T3_WT.merge.counts.anno.pval.txt 1.2\n",
      "HK2_T3_WT.1_2.bed\n",
      "(236, 12) --> HK2_T1_WT.merge.counts.anno.pval.txt 1.5\n",
      "HK2_T1_WT.1_5.bed\n",
      "(174, 12) --> HK2_T2_WT.merge.counts.anno.pval.txt 1.5\n",
      "HK2_T2_WT.1_5.bed\n",
      "(2746, 12) --> HK2_T3_WT.merge.counts.anno.pval.txt 1.5\n",
      "HK2_T3_WT.1_5.bed\n"
     ]
    }
   ],
   "source": [
    "peakFiles = glob.glob('*.pval.txt')\n",
    "peakFiles.sort()\n",
    "for th, name in zip(ths, names):\n",
    "    for peakFile in peakFiles:\n",
    "        peakDf = pd.read_csv(peakFile, sep='\\t', header=None, skiprows=[0])\n",
    "        subId = peakDf.iloc[:,4].div(peakDf.iloc[:,5]) >= th\n",
    "        print(peakDf[subId].shape,'-->', peakFile, f'{th}')\n",
    "        outFile = peakFile.split(\".\")[0] + f'.{name}.bed'\n",
    "        print(outFile)\n",
    "        peakDf[subId].iloc[:, [0,1,2]].to_csv(f'{outFile}', sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 find the T1 T2 T3 overlapped peaks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# login a new node and copy the bash command \n",
    "```bash\n",
    "module load epd/7.3-2                                                     \n",
    "module load python-packages/2.7                                           \n",
    "module load R/2.15.3                                                      \n",
    "module load bowtie/1.1.0                                                  \n",
    "module load tophat/2.1.0                                                  \n",
    "#module load samtools/1.6                                                 \n",
    "module load samtools/0.1.19                                               \n",
    "export PYTHONPATH=/home/jlyu/xc3/software/python/site-packages:$PYTHONPATH\n",
    "\n",
    "```\n",
    "```bash\n",
    "python /home/jlyu/xc3/software/bed_overlap3.py -v HK2.all.1_2.venn.pdf -i HK2.all.1_2.bed HK2_T1_WT.1_2.bed HK2_T2_WT.1_2.bed HK2_T3_WT.1_2.bed\n",
    "python /home/jlyu/xc3/software/bed_overlap3.py -v HK2.all.1_5.venn.pdf -i HK2.all.1_5.bed HK2_T1_WT.1_5.bed HK2_T2_WT.1_5.bed HK2_T3_WT.1_5.bed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /home/jlyu/xc3/software/bed_overlap3.py -v HK2.all.1_2.venn.pdf -i HK2.all.1_2.bed HK2_T1_WT.1_2.bed HK2_T2_WT.1_2.bed HK2_T3_WT.1_2.bed\n",
      "python /home/jlyu/xc3/software/bed_overlap3.py -v HK2.all.1_5.venn.pdf -i HK2.all.1_5.bed HK2_T1_WT.1_5.bed HK2_T2_WT.1_5.bed HK2_T3_WT.1_5.bed\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(names):\n",
    "    bedFiles = [glob.glob(f'*{treat}*{name}.bed')[0] for treat in ['T1','T2','T3']]\n",
    "    outBed = f'{exp}.all.{name}.bed'\n",
    "    outVenn = f'{exp}.all.{name}.venn.pdf'\n",
    "    bed_files_format = ' '.join(bedFiles)\n",
    "    line = 'python /home/jlyu/xc3/software/bed_overlap3.py -v {} -i {} {}'.format(outVenn, outBed, bed_files_format)\n",
    "    print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HK2.all.1_2.bed\t\t\t      HK2_T2_WT.1_5.bed\r\n",
      "HK2.all.1_5.bed\t\t\t      HK2_T2_WT.merge.counts.anno.pval.txt\r\n",
      "HK2_T1_WT.1_2.bed\t\t      HK2_T3_WT.1_2.bed\r\n",
      "HK2_T1_WT.1_5.bed\t\t      HK2_T3_WT.1_5.bed\r\n",
      "HK2_T1_WT.merge.counts.anno.pval.txt  HK2_T3_WT.merge.counts.anno.pval.txt\r\n",
      "HK2_T2_WT.1_2.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Redraw the venn diagram for the shared 1.2 1.5 peaks\n",
    "the results depends hong whether like it or not (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Extract the signal for heatmap\n",
    "using the previous above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR>1){print $1,$2,$3,\"none\",\".\",\"+\"}}' HK2.all.1_2.bed > HK2.all.1_2.heat.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR>1){print $1,$2,$3,\"none\",\".\",\"+\"}}' HK2.all.1_5.bed > HK2.all.1_5.heat.bed\n"
     ]
    }
   ],
   "source": [
    "#format the bed file into the bed file add three columns more; \n",
    "for name in names:\n",
    "    Bed = f'{exp}.all.{name}.bed'\n",
    "    outBed = f'{exp}.all.{name}.heat.bed'\n",
    "    line = \"awk 'BEGIN{OFS=\\\"\\\\t\\\"}{if (NR>1){print $1,$2,$3,\\\"none\\\",\\\".\\\",\\\"+\\\"}}'\" + f' {Bed} > {outBed}'\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HK2.all.1_2.bed\t\t\t      HK2_T2_WT.1_2.bed\r\n",
      "HK2.all.1_2.heat.bed\t\t      HK2_T2_WT.1_5.bed\r\n",
      "HK2.all.1_5.bed\t\t\t      HK2_T2_WT.merge.counts.anno.pval.txt\r\n",
      "HK2.all.1_5.heat.bed\t\t      HK2_T3_WT.1_2.bed\r\n",
      "HK2_T1_WT.1_2.bed\t\t      HK2_T3_WT.1_5.bed\r\n",
      "HK2_T1_WT.1_5.bed\t\t      HK2_T3_WT.merge.counts.anno.pval.txt\r\n",
      "HK2_T1_WT.merge.counts.anno.pval.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bin size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T1_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T2_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T3_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_Y78A_treat.nsp.bw -R HK2.all.1_2.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o 1_2.Ts.ENL.peak.gz -p 8\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T1_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T2_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T3_treat.nsp.bw /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_Y78A_treat.nsp.bw -R HK2.all.1_5.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o 1_5.Ts.ENL.peak.gz -p 8\n"
     ]
    }
   ],
   "source": [
    "bwpath = '/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/'\n",
    "# exp = 'HK2'\n",
    "exp = '293'\n",
    "bwfiles = glob.glob(bwpath+exp+'*.bw')\n",
    "bwfiles.sort()\n",
    "bwfiles = bwfiles[:5]\n",
    "for name in names:\n",
    "    outBed = f'{exp}.all.{name}.heat.bed'\n",
    "    line = 'computeMatrix reference-point --referencePoint center -S {} -R {} --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o {}.Ts.ENL.peak.gz -p 8'.format(' '.join(bwfiles), outBed, '{}'.format(name))\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotHeatmap --sortUsingSamples 1 -m 1_2.Ts.ENL.peak.gz -out HK2.1_2.peak.pdf --outFileNameMatrix 1_2.heatmap.peak.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center\n",
      "plotHeatmap --sortUsingSamples 1 -m 1_5.Ts.ENL.peak.gz -out HK2.1_5.peak.pdf --outFileNameMatrix 1_5.heatmap.peak.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center\n"
     ]
    }
   ],
   "source": [
    "# plot the heatmap\n",
    "for name in names:\n",
    "    line = 'plotHeatmap --sortUsingSamples 1 -m {}.Ts.ENL.peak.gz -out HK2.{}.peak.pdf --outFileNameMatrix {} --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 10 --refPointLabel center'.format(name, name, name+'.heatmap.peak.mat')\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replot the heatmap with shorter height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"plotHeatmap --sortUsingSamples 1 -m 1_5.Ts.ENL.peak.gz -out HK2.1_5.peak.pdf --outFileNameMatrix 1_5.heatmap.peak.mat --colorMap Blues Blues Blues Blues Blues --dpi 300 --heatmapHeight 5 --refPointLabel center\"\n",
    "print(line)\n",
    "os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the table for the peak heatmap using peak center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_deeptools_gz_to_df(file_name):\n",
    "    \"\"\"\n",
    "    file_name: the deeptools computeMatrix output matrix gz file\n",
    "    caculate the avg signal per sample across all the bins\n",
    "    \"\"\"\n",
    "    with gzip.open(file_name, 'rt', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    line = lines[0]\n",
    "    a = line.split('@')[-1].split('\\\\')[0]\n",
    "    a = re.sub('true', 'True', a)\n",
    "    a = re.sub('false', 'False', a)\n",
    "    a = re.sub('null', 'False', a)    \n",
    "    info = eval(a)\n",
    "    with open(f'{file_name}.txt', 'w') as f:\n",
    "        f.writelines(lines[1:])\n",
    "\n",
    "    df = pd.read_csv(f'{file_name}.txt', sep='\\t', header=None) \n",
    "    for i, sample in enumerate(info['sample_labels']):\n",
    "        start = info['sample_boundaries'][i] + 6\n",
    "        end = info['sample_boundaries'][i+1] + 6    \n",
    "        df[sample] = df.iloc[:, start:end].mean(axis=1)\n",
    "\n",
    "    df.sort_values(by=[info['sample_labels'][0]], inplace=True, ascending=False)     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2.Ts.ENL.peak.gz\tHK21_2.peak.sig.txt\r\n",
      "1_2.Ts.ENL.peak.gz.txt\tHK21_5.peak.sig.txt\r\n",
      "1_2.heatmap.peak.mat\tHK2_T1_WT.1_2.bed\r\n",
      "1_5.Ts.ENL.peak.gz\tHK2_T1_WT.1_5.bed\r\n",
      "1_5.Ts.ENL.peak.gz.txt\tHK2_T1_WT.merge.counts.anno.pval.txt\r\n",
      "1_5.heatmap.peak.mat\tHK2_T2_WT.1_2.bed\r\n",
      "HK2.1_2.peak.pdf\tHK2_T2_WT.1_5.bed\r\n",
      "HK2.1_5.peak.pdf\tHK2_T2_WT.merge.counts.anno.pval.txt\r\n",
      "HK2.all.1_2.bed\t\tHK2_T3_WT.1_2.bed\r\n",
      "HK2.all.1_2.heat.bed\tHK2_T3_WT.1_5.bed\r\n",
      "HK2.all.1_5.bed\t\tHK2_T3_WT.merge.counts.anno.pval.txt\r\n",
      "HK2.all.1_5.heat.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    df = convert_deeptools_gz_to_df(file_name = f'{name}.Ts.ENL.peak.gz')\n",
    "    df.iloc[:, [0,1,2,3,4,5,-5,-4,-3,-2,-1]].to_csv(f'{exp}{name}.peak.sig.txt', index=False, sep='\\t') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add the delta heatmap for the above sampels\n",
    "Just heard back from Liling, actually she wants to change the delta heatmap color theme back to grey/black and orange that we used before. Could you please make this change for all the delta heatmap? In the FC >1.2 and FC>1.5 delta heatmap, right now we only have signals for wt, T1, T2 and T3, please add T1-wt, T2-wt and T3-wt. Attached is an old version of this figure for your reference, keep the blue color for individual sample, use the same organge-black/grey for delta map, but no need to label gene names on the right. **2018-8-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2.Ts.ENL.peak.gz  1_5.Ts.ENL.peak.gz\n",
      "HK2.1_2.peak.pdf  HK2.1_5.peak.pdf\n"
     ]
    }
   ],
   "source": [
    "!ls *.gz\n",
    "!ls *.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the table for the peak region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for formating the chr start end into bed format\n",
    "# if the last column has sign ('+' or '-'), then prepare to swap tss and tes for '-'\n",
    "def convert_region_to_bed(bedfile, outname, header=0):\n",
    "    df = pd.read_csv(bedfile,sep='\\t',header=header)\n",
    "    df.columns = np.arange(0,df.shape[1])\n",
    "    # detect the strand and swap the start end when negative strand\n",
    "    # the last column should be strand\n",
    "    if df.iloc[0,-1] == '-' or df.iloc[0,-1] == '+':\n",
    "        idx = df.iloc[:,-1] == '-'\n",
    "        # swap the tss tes according to the strand\n",
    "        df.loc[idx,[1,2]] = df.loc[idx,[2,1]].values\n",
    "        # modify the strand\n",
    "        df.iloc[:,-1] = '+'\n",
    "        \n",
    "    df.loc[:,3] = np.arange(df.shape[0])# for gene name column\n",
    "    df.loc[:,4] = 0 # for bed format (value)\n",
    "    df.loc[:,5] = '+'\n",
    "    df = df.reindex(range(6), axis='columns')\n",
    "    print('writing the output --> {}'.format(outname))\n",
    "    print(f'{outname} --->: reformated bed_file as the input of the bigWigAverageoverBed')\n",
    "    df.to_csv(outname,sep='\\t',index=False,header=None)\n",
    "    \n",
    "    \n",
    "def comp_avg_sig_from_bw_by_bed(bedfile, bw_files, which_column=2):\n",
    "    \"\"\"\n",
    "    bedfile: the input merged bedfile which needs to extract the signal from\n",
    "    bw_files: list of bw files whose signal is extracted from\n",
    "    which_column: 3 is the acutal counts column, 4 is the acutal avg signal column;\n",
    "    but, we need to use the first column as index, then 2 is the counts column;\n",
    "    outname: reformat the bedfile to the normal 6 columns bed file\n",
    "    will save the output file in the same folder as the bedfile\n",
    "    \"\"\"\n",
    "    outname = bedfile.split('.bed')[0] + '.str.bed'\n",
    "    # convert the 3 columns bed to the normal bed file\n",
    "    convert_region_to_bed(bedfile, outname)\n",
    "    for i,bw_file in enumerate(bw_files):\n",
    "        command = line = f'~/xc3/software/bigWigAverageOverBed {bw_file} {outname} avg_sig_{i}.txt'\n",
    "        print('execute --> {}'.format(command))\n",
    "        os.system(command)\n",
    "    dfs = []\n",
    "    for i in range(len(bw_files)):\n",
    "        dfs.append(pd.read_csv(f'avg_sig_{i}.txt',sep='\\t',header=None, index_col=0))\n",
    "    df = pd.DataFrame([dfs[0].iloc[:,0]] + # iloc[:,0]: the width\n",
    "                      [dfi.iloc[:,which_column] for dfi in dfs]).T # conbine the columns together\n",
    "    df.columns = ['width'] + [bw_file.split('/')[-1].split('.')[0] for bw_file in bw_files]\n",
    "    df_bed = pd.read_csv(bedfile, sep='\\t', header=None, names = ['chr', 'start', 'end'])\n",
    "    df_out = df_bed.join(df)\n",
    "    print(f\"output file -->: {bedfile.split('.bed')[0] + '.counts.txt'}\")\n",
    "    df_out.to_csv(bedfile.split('.bed')[0] + '.counts.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate the signal for HK2.all.1_2.bed\n",
      "writing the output --> HK2.all.1_2.str.bed\n",
      "HK2.all.1_2.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw HK2.all.1_2.str.bed avg_sig_0.txt\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T1_treat.nsp.bw HK2.all.1_2.str.bed avg_sig_1.txt\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T2_treat.nsp.bw HK2.all.1_2.str.bed avg_sig_2.txt\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T3_treat.nsp.bw HK2.all.1_2.str.bed avg_sig_3.txt\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_Y78A_treat.nsp.bw HK2.all.1_2.str.bed avg_sig_4.txt\n",
      "output file -->: HK2.all.1_2.counts.txt\n",
      "generate the signal for HK2.all.1_5.bed\n",
      "writing the output --> HK2.all.1_5.str.bed\n",
      "HK2.all.1_5.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw HK2.all.1_5.str.bed avg_sig_0.txt\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T1_treat.nsp.bw HK2.all.1_5.str.bed avg_sig_1.txt\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T2_treat.nsp.bw HK2.all.1_5.str.bed avg_sig_2.txt\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T3_treat.nsp.bw HK2.all.1_5.str.bed avg_sig_3.txt\n",
      "execute --> ~/xc3/software/bigWigAverageOverBed /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_Y78A_treat.nsp.bw HK2.all.1_5.str.bed avg_sig_4.txt\n",
      "output file -->: HK2.all.1_5.counts.txt\n"
     ]
    }
   ],
   "source": [
    "exp = 'HK2'\n",
    "bwfiles = glob.glob(bwpath+exp+'*.bw')\n",
    "bwfiles.sort()\n",
    "bwfiles = bwfiles[:5]\n",
    "for name in names:\n",
    "    bed_file = f'{exp}.all.{name}.bed'\n",
    "    print('generate the signal for',bed_file)\n",
    "    comp_avg_sig_from_bw_by_bed(bed_file, bwfiles, 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-rank the file accordi ng to the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_row(row):\n",
    "    row = [str(ele) for ele in row]\n",
    "    return '|'.join(row)\n",
    "\n",
    "for name in names:\n",
    "    df1 = pd.read_csv(f'{name}.peak.sig.txt', sep='\\t')\n",
    "    df1.index = df1.iloc[:,:3].apply(combine_row, axis=1)\n",
    "    df2 = pd.read_csv(f'{exp}.all.{name}.counts.txt', sep='\\t')\n",
    "    df2.index = df2.iloc[:,:3].apply(combine_row, axis=1)\n",
    "    df2 = df2.reindex(df1.index)\n",
    "    df2.to_csv(f'{exp}.all.{name}.sig.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annoate_bed_to_gene(infile, outfile, cutoff=5000):\n",
    "    ref, tss_set = {}, set()\n",
    "    reffile = '/mount/weili3/xc3/genomes/hg19.refGene.txt'\n",
    "    for line in open(reffile):\n",
    "        col = line.split('\\t')\n",
    "        name, cr, strand, TSS, TES, symbol = col[1], col[2], col[3], int(col[4]), int(col[5]), col[12]\n",
    "        if strand == '-': TSS, TES = TES, TSS\n",
    "        if cr not in ref: ref[cr] = []\n",
    "        if (cr,TSS,strand) not in tss_set:\n",
    "            ref[cr].append((name,symbol,strand,TSS,TES))\n",
    "            tss_set.add((cr,TSS,strand))\n",
    "    for cr in ref: ref[cr].append(('none','none','none',0,0))\n",
    "    \n",
    "    # annotate the file\n",
    "    text = open(infile).readlines()\n",
    "    fout = open(outfile, 'w')\n",
    "    print('processing on {}\\n will output {}\\n'.format(infile,outfile))\n",
    "    for line in text:\n",
    "        col = line.split('\\t')\n",
    "        try: cr, start, end = col[0], int(col[1]), int(col[2])\n",
    "        except: \n",
    "            fout.write(line[:-1]+'\\twithin_genebody\\tnearest_TSS\\tdistance\\n')\n",
    "            continue\n",
    "        if cr not in ref: continue\n",
    "        peak = (start + end) / 2\n",
    "        genes, genebody, genes0, genebody0 = [], [], [], []\n",
    "        for name, symbol, strand, TSS, TES in ref[cr]:\n",
    "            if strand == '+':\n",
    "                dist = end - TSS\n",
    "                if abs(start-TSS)<abs(dist):dist=start-TSS\n",
    "\n",
    "            elif strand == '-':\n",
    "                dist = TSS - end\n",
    "                if abs(TSS - start)<abs(dist):dist=TSS - start\n",
    "\n",
    "            elif strand != 'none': raise ValueError\n",
    "            if abs(dist) <= cutoff: genes.append((abs(dist),symbol,dist)) \n",
    "            if (start - TSS) * (start - TES) <= 0: genebody.append((abs(dist),symbol,dist))\n",
    "            elif (end - TSS) * (end - TES) <= 0: genebody.append((abs(dist),symbol,dist))\n",
    "            elif (start - TSS) * (end - TES) <=0: genebody.append((abs(dist),symbol,dist))\n",
    "        genes, genebody = sorted(genes), sorted(genebody)\n",
    "        for g in sorted(genes):\n",
    "            if g[1] not in [x[1] for x in genes0]: genes0.append(g)\n",
    "        for g in sorted(genebody):\n",
    "            if g[1] not in [x[1] for x in genebody0]: genebody0.append(g)\n",
    "        if any(genes0):\n",
    "            symbols = ','.join([x[1] for x in genes0])\n",
    "            dists = ','.join(['%d' % x[2] for x in sorted(genes0)])\n",
    "        else: symbols, dists = 'none', 'none'\n",
    "        if any(genebody): body = ','.join([x[1] for x in genebody0])\n",
    "        else: body = 'none'\n",
    "        fout.write(line[:-1] + '\\t%s\\t%s\\t%s\\n' % (body,symbols,dists))\n",
    "    fout.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2.Ts.ENL.peak.gz\tHK2.all.1_5.bed\r\n",
      "1_2.Ts.ENL.peak.gz.txt\tHK2.all.1_5.counts.txt\r\n",
      "1_2.heatmap.peak.mat\tHK2.all.1_5.heat.bed\r\n",
      "1_5.Ts.ENL.peak.gz\tHK2.all.1_5.str.bed\r\n",
      "1_5.Ts.ENL.peak.gz.txt\tHK2_T1_WT.1_2.bed\r\n",
      "1_5.heatmap.peak.mat\tHK2_T1_WT.1_5.bed\r\n",
      "HK2.1_2.peak.pdf\tHK2_T1_WT.merge.counts.anno.pval.txt\r\n",
      "HK2.1_2.peak.sig.txt\tHK2_T2_WT.1_2.bed\r\n",
      "HK2.1_5.peak.pdf\tHK2_T2_WT.1_5.bed\r\n",
      "HK2.1_5.peak.sig.txt\tHK2_T2_WT.merge.counts.anno.pval.txt\r\n",
      "HK2.all.1_2.bed\t\tHK2_T3_WT.1_2.bed\r\n",
      "HK2.all.1_2.counts.txt\tHK2_T3_WT.1_5.bed\r\n",
      "HK2.all.1_2.heat.bed\tHK2_T3_WT.merge.counts.anno.pval.txt\r\n",
      "HK2.all.1_2.str.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing on HK2.1_2.peak.sig.txt\n",
      " will output HK2.all.1_2.sig.anno.txt\n",
      "\n",
      "processing on HK2.1_5.peak.sig.txt\n",
      " will output HK2.all.1_5.sig.anno.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    annoate_bed_to_gene(f'{exp}.{name}.peak.sig.txt', f'{exp}.all.{name}.sig.anno.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the coup delta heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR>1){print $1,$2,$3,NR-2,\".\",\"+\"}}' 293.all.1_2.sig.anno.txt > 293.all.1_2.new.heat.bed\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR>1){print $1,$2,$3,NR-2,\".\",\"+\"}}' 293.all.1_5.sig.anno.txt > 293.all.1_5.new.heat.bed\n"
     ]
    }
   ],
   "source": [
    "#format the bed file into the bed file add three columns more; \n",
    "names = ['1_2','1_5']\n",
    "for name in names:\n",
    "    Bed = f'{exp}.all.{name}.sig.anno.txt'\n",
    "    outBed = f'{exp}.all.{name}.new.heat.bed'\n",
    "    line = \"awk 'BEGIN{OFS=\\\"\\\\t\\\"}{if (NR>0){print $1,$2,$3,NR-2,\\\".\\\",\\\"+\\\"}}'\" + f' {Bed} > {outBed}'\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = 'ENL'\n",
    "treats = ['T1', 'T2', 'T3', 'Y78A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T1_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T1_treat.nsp.bw -R HK2.all.1_2.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_HK2_F_T1_co-UP_genes.gz -p 8\n",
      "****\n",
      "\n",
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T2_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T2_treat.nsp.bw -R HK2.all.1_2.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_HK2_F_T2_co-UP_genes.gz -p 8\n",
      "****\n",
      "\n",
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T3_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_T3_treat.nsp.bw -R HK2.all.1_2.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_HK2_F_T3_co-UP_genes.gz -p 8\n",
      "****\n",
      "\n",
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_Y78A_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_Y78A_treat.nsp.bw -R HK2.all.1_2.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_HK2_F_Y78A_co-UP_genes.gz -p 8\n",
      "****\n",
      "\n",
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/HK2_F_ENL_treat.nsp.bw -R HK2.all.1_2.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_HK2_F_ENL_co-UP_genes.gz -p 8\n",
      "****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = treats + [ctrl]\n",
    "for sample in samples:\n",
    "    bwfile = glob.glob(bwpath + exp + '*' + sample + '*.bw')[0]\n",
    "    outBed = f\"{exp}.all.1_2.new.heat.bed\"\n",
    "    print(bwfile)\n",
    "    line = f'computeMatrix reference-point --referencePoint center -S {bwfile} -R {outBed} --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_{exp}_F_{sample}_co-UP_genes.gz -p 8'\n",
    "    print(line + '\\n****\\n')\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8564\n",
      "drwxr-xr-x  2 jlyu lilab    4096 Oct  3 23:45 .\n",
      "-rw-r--r--  1 jlyu lilab    1653 Oct  3 23:41 293.all.1_5.new.heat.bed\n",
      "-rw-r--r--  1 jlyu lilab    8079 Oct  3 23:41 293.all.1_2.new.heat.bed\n",
      "-rw-r--r--  1 jlyu lilab   25044 Oct  3 23:41 293.all.1_2.sig.anno.txt\n",
      "-rw-r--r--  1 jlyu lilab    5691 Oct  3 23:41 293.all.1_5.sig.anno.txt\n",
      "drwxr-xr-x 11 jlyu lilab    4096 Oct  3 22:51 ..\n",
      "-rw-r--r--  1 jlyu lilab   15726 Oct  3 22:15 PeakMatrix_HK2_F_ENL_co-UP_genes.1_5.gz\n",
      "-rw-r--r--  1 jlyu lilab   14997 Oct  3 22:15 PeakMatrix_HK2_F_Y78A_co-UP_genes.1_5.gz\n",
      "-rw-r--r--  1 jlyu lilab   17514 Oct  3 22:15 PeakMatrix_HK2_F_T3_co-UP_genes.1_5.gz\n",
      "-rw-r--r--  1 jlyu lilab   16699 Oct  3 22:15 PeakMatrix_HK2_F_T2_co-UP_genes.1_5.gz\n",
      "-rw-r--r--  1 jlyu lilab   17019 Oct  3 22:15 PeakMatrix_HK2_F_T1_co-UP_genes.1_5.gz\n",
      "-rw-r--r--  1 jlyu lilab  616084 Aug 28 00:10 TsWT.sorted.bed\n",
      "-rw-r--r--  1 jlyu lilab   52286 Aug 18 03:38 PeakMatrix_HK2_F_ENL_co-UP_genes.gz\n",
      "-rw-r--r--  1 jlyu lilab   50352 Aug 18 03:38 PeakMatrix_HK2_F_Y78A_co-UP_genes.gz\n",
      "-rw-r--r--  1 jlyu lilab   56482 Aug 18 03:38 PeakMatrix_HK2_F_T3_co-UP_genes.gz\n",
      "-rw-r--r--  1 jlyu lilab   54149 Aug 18 03:38 PeakMatrix_HK2_F_T2_co-UP_genes.gz\n",
      "-rw-r--r--  1 jlyu lilab   54904 Aug 18 03:38 PeakMatrix_HK2_F_T1_co-UP_genes.gz\n",
      "-rw-r--r--  1 jlyu lilab    2068 Aug 18 03:35 HK2.all.1_5.new.heat.bed\n",
      "-rw-r--r--  1 jlyu lilab    7503 Aug 18 03:35 HK2.all.1_2.new.heat.bed\n",
      "-rw-r--r--  1 jlyu lilab    9729 Aug 18 03:29 HK2.all.1_5.sig.anno.txt\n",
      "-rw-r--r--  1 jlyu lilab   33513 Aug 18 03:29 HK2.all.1_2.sig.anno.txt\n",
      "-rw-r--r--  1 jlyu lilab    5255 Aug 18 03:13 HK2.all.1_5.counts.txt\n",
      "-rw-r--r--  1 jlyu lilab    2068 Aug 18 03:13 HK2.all.1_5.str.bed\n",
      "-rw-r--r--  1 jlyu lilab   18005 Aug 18 03:13 HK2.all.1_2.counts.txt\n",
      "-rw-r--r--  1 jlyu lilab    7504 Aug 18 03:13 HK2.all.1_2.str.bed\n",
      "-rw-r--r--  1 jlyu lilab    7936 Aug 18 02:56 HK2.1_5.peak.sig.txt\n",
      "-rw-r--r--  1 jlyu lilab  322365 Aug 18 02:56 1_5.Ts.ENL.peak.gz.txt\n",
      "-rw-r--r--  1 jlyu lilab   28027 Aug 18 02:56 HK2.1_2.peak.sig.txt\n",
      "-rw-r--r--  1 jlyu lilab 1124209 Aug 18 02:56 1_2.Ts.ENL.peak.gz.txt\n",
      "-rw-r--r--  1 jlyu lilab  483303 Aug 17 23:01 HK2.1_5.peak.pdf\n",
      "-rw-r--r--  1 jlyu lilab  183927 Aug 17 23:00 1_5.heatmap.peak.mat\n",
      "-rw-r--r--  1 jlyu lilab  683268 Aug 17 22:57 HK2.1_2.peak.pdf\n",
      "-rw-r--r--  1 jlyu lilab  601101 Aug 17 22:57 1_2.heatmap.peak.mat\n",
      "-rw-r--r--  1 jlyu lilab   73558 Aug 17 22:55 1_5.Ts.ENL.peak.gz\n",
      "-rw-r--r--  1 jlyu lilab  247433 Aug 17 22:55 1_2.Ts.ENL.peak.gz\n",
      "-rw-r--r--  1 jlyu lilab    2212 Aug 17 22:52 HK2.all.1_5.heat.bed\n",
      "-rw-r--r--  1 jlyu lilab    7852 Aug 17 22:52 HK2.all.1_2.heat.bed\n",
      "-rw-r--r--  1 jlyu lilab    1623 Aug 17 22:51 HK2.all.1_5.bed\n",
      "-rw-r--r--  1 jlyu lilab    5724 Aug 17 22:51 HK2.all.1_2.bed\n",
      "-rw-r--r--  1 jlyu lilab   65547 Aug 17 22:44 HK2_T3_WT.1_5.bed\n",
      "-rw-r--r--  1 jlyu lilab    4155 Aug 17 22:44 HK2_T2_WT.1_5.bed\n",
      "-rw-r--r--  1 jlyu lilab    5677 Aug 17 22:44 HK2_T1_WT.1_5.bed\n",
      "-rw-r--r--  1 jlyu lilab  229359 Aug 17 22:44 HK2_T3_WT.1_2.bed\n",
      "-rw-r--r--  1 jlyu lilab   22435 Aug 17 22:44 HK2_T2_WT.1_2.bed\n",
      "-rw-r--r--  1 jlyu lilab   15366 Aug 17 22:44 HK2_T1_WT.1_2.bed\n",
      "-rw-r--r--  1 jlyu lilab 1336498 Aug 17 22:32 HK2_T3_WT.merge.counts.anno.pval.txt\n",
      "-rw-r--r--  1 jlyu lilab 1022305 Aug 17 22:32 HK2_T2_WT.merge.counts.anno.pval.txt\n",
      "-rw-r--r--  1 jlyu lilab 1007604 Aug 17 22:32 HK2_T1_WT.merge.counts.anno.pval.txt\n",
      "chr\tstart\tend\t-1\t.\t+\n",
      "chr7\t5457629\t5470124\t0\t.\t+\n",
      "chr7\t27197889\t27240775\t1\t.\t+\n",
      "chr6\t32934633\t32953286\t2\t.\t+\n",
      "chr17\t47071074\t47082171\t3\t.\t+\n",
      "chr7\t27177319\t27193139\t4\t.\t+\n",
      "chr17\t46618157\t46623367\t5\t.\t+\n",
      "chr7\t23506256\t23512030\t6\t.\t+\n",
      "chr7\t26222169\t26248779\t7\t.\t+\n",
      "chr9\t89559679\t89563051\t8\t.\t+\n"
     ]
    }
   ],
   "source": [
    "!ls -alt\n",
    "!head 293.all.1_5.new_heat.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw -R 293.all.1_5.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_293_F_T1_co-UP_genes.1_5.gz -p 8\n",
      "****\n",
      "\n",
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw -R 293.all.1_5.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_293_F_T2_co-UP_genes.1_5.gz -p 8\n",
      "****\n",
      "\n",
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw -R 293.all.1_5.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_293_F_T3_co-UP_genes.1_5.gz -p 8\n",
      "****\n",
      "\n",
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw -R 293.all.1_5.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_293_F_Y78A_co-UP_genes.1_5.gz -p 8\n",
      "****\n",
      "\n",
      "/mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw\n",
      "computeMatrix reference-point --referencePoint center -S /mount/weili2/lilab/xc3/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw -R 293.all.1_5.new.heat.bed --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_293_F_ENL_co-UP_genes.1_5.gz -p 8\n",
      "****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp = '293'\n",
    "samples = treats + [ctrl]\n",
    "for sample in samples:\n",
    "    bwfile = glob.glob(bwpath + exp + '*' + sample + '*.bw')[0]\n",
    "    outBed = f\"{exp}.all.1_5.new.heat.bed\"\n",
    "    print(bwfile)\n",
    "    line = f'computeMatrix reference-point --referencePoint center -S {bwfile} -R {outBed} --beforeRegionStartLength 5000 --afterRegionStartLength 5000 --binSize 100 --skipZeros --missingDataAsZero -o PeakMatrix_{exp}_F_{sample}_co-UP_genes.1_5.gz -p 8'\n",
    "    print(line + '\\n****\\n')\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outer_links(files):\n",
    "    public_url_pre = \"http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/\"\n",
    "    public_url_folder = \"/mount/weili2/lilab/xc3/ENL2/ChIP/tmp/\"\n",
    "    for ifile in files:\n",
    "        file_name = ifile.split('/')[-1]\n",
    "        line = f\"cp {ifile} {public_url_folder}{ifile}\"\n",
    "        print(line)\n",
    "        os.system(line)\n",
    "        print(f'{public_url_pre}{ifile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PeakMatrix_293_F_T1_co-UP_genes.1_5.gz', 'PeakMatrix_293_F_T2_co-UP_genes.1_5.gz', 'PeakMatrix_293_F_T3_co-UP_genes.1_5.gz', 'PeakMatrix_293_F_Y78A_co-UP_genes.1_5.gz', 'PeakMatrix_293_F_ENL_co-UP_genes.1_5.gz']\n"
     ]
    }
   ],
   "source": [
    "public_url_pre = \"http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/\"\n",
    "public_url_folder = \"/mount/weili2/lilab/xc3/ENL2/ChIP/tmp/\"\n",
    "work_path = \"/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks/\"\n",
    "#files = glob.glob(work_path + '*293*1_5.gz')\n",
    "files = glob.glob('*293*1_5.gz')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp /home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks/PeakMatrix_293_F_T1_co-UP_genes.1_5.gz /mount/weili2/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_T1_co-UP_genes.1_5.gz\n",
      "http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_T1_co-UP_genes.1_5.gz\n",
      "cp /home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks/PeakMatrix_293_F_T2_co-UP_genes.1_5.gz /mount/weili2/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_T2_co-UP_genes.1_5.gz\n",
      "http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_T2_co-UP_genes.1_5.gz\n",
      "cp /home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks/PeakMatrix_293_F_T3_co-UP_genes.1_5.gz /mount/weili2/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_T3_co-UP_genes.1_5.gz\n",
      "http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_T3_co-UP_genes.1_5.gz\n",
      "cp /home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks/PeakMatrix_293_F_Y78A_co-UP_genes.1_5.gz /mount/weili2/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_Y78A_co-UP_genes.1_5.gz\n",
      "http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_Y78A_co-UP_genes.1_5.gz\n",
      "cp /home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/4.coup_peaks/PeakMatrix_293_F_ENL_co-UP_genes.1_5.gz /mount/weili2/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_ENL_co-UP_genes.1_5.gz\n",
      "http://dldcc-web.brc.bcm.edu/lilab/xc3/ENL2/ChIP/tmp/PeakMatrix_293_F_ENL_co-UP_genes.1_5.gz\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for ifile in files:\n",
    "    source = work_path + ifile\n",
    "    symbol = public_url_folder + ifile\n",
    "    line = f\"cp {source} {public_url_folder}{ifile}\"\n",
    "    print(line)\n",
    "    os.system(line)\n",
    "    print(f'{public_url_pre}{ifile}')\n",
    "    \n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Motif analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1） 333 genes with FC>1.2 enhanced binding; 2）87 genes with FC>1.5; 3) T3 vs.WT FC>1.5 enhanced binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "workPath = '/home/jlyu/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/Run_On_Lvjie/6.res_motif/'\n",
    "os.chdir(workPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 extract the sequence for the three gene lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process on T1_2_3 co-UP FC1.2.txt\n",
      "process on T1_2_3 co-UP FC1.5.txt\n",
      "process on 293_T3_WT.merge.counts.anno.genes1_5.txt\n"
     ]
    }
   ],
   "source": [
    "# read the gene's tss and tes and save to the bed file\n",
    "geneLists = ['T1_2_3 co-UP FC1.2.txt', 'T1_2_3 co-UP FC1.5.txt', '293_T3_WT.merge.counts.anno.genes1_5.txt']\n",
    "names = ['coup.1_2', 'coup.1_5', 'T3WT.1_5']\n",
    "gene_list = geneLists[0]\n",
    "for i, gene_list in enumerate(geneLists):\n",
    "    with open(gene_list, 'r') as f:\n",
    "        genes = f.readlines()\n",
    "        genes = [gene.rstrip() for gene in genes]\n",
    "        df = df_genes.reindex(genes)\n",
    "        df.loc[:,'strand'] = '+'\n",
    "        print(f'process on {gene_list}')\n",
    "        df['tes'] = df['tss'] + 2000\n",
    "        df['tss'] = df['tss'] - 2000\n",
    "        df.to_csv(f'{names[i]}.motif.bed', sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HK2.all.1_2.new.heat.bed  HK2.all.1_2.sig.anno.txt  HK2.all.1_5.new.heat.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR>0) {mid = int( ($2+$3) / 2); print $1, mid-2000, mid+2000, $4, $5, $6;}}' HK2.all.1_2.new.heat.bed> 1_2.motif.tmp.txt\n",
      "bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed 1_2.motif.tmp.txt -fo 1_2.motif.txt\n",
      "awk '!a[$0]++' 1_2.motif.txt > 1_2.motif.uniq.txt\n",
      "awk 'BEGIN{OFS=\"\\t\"}{if (NR>0) {mid = int( ($2+$3) / 2); print $1, mid-2000, mid+2000, $4, $5, $6;}}' HK2.all.1_5.new.heat.bed> 1_5.motif.tmp.txt\n",
      "bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed 1_5.motif.tmp.txt -fo 1_5.motif.txt\n",
      "awk '!a[$0]++' 1_5.motif.txt > 1_5.motif.uniq.txt\n"
     ]
    }
   ],
   "source": [
    "# extract the sequence for the corrdinates\n",
    "names = ['1_2', '1_5']\n",
    "for name in names:\n",
    "    bedFile = f'HK2.all.{name}.new.heat.bed'\n",
    "    outTxt1 = f'{name}.motif.tmp.txt'\n",
    "    line = \"awk 'BEGIN{OFS=\\\"\\\\t\\\"}{if (NR>0) {mid = int( ($2+$3) / 2); print $1, mid-2000, mid+2000, $4, $5, $6;}}\\' \" + bedFile + f\"> {outTxt1}\"\n",
    "    print(line)\n",
    "    os.system(line)\n",
    "    outTxt = f'{name}.motif.txt'\n",
    "    line = f\"bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed {outTxt1} -fo {outTxt}\"\n",
    "    print(line)\n",
    "    os.system(line)\n",
    "    line = \"awk \\'!a[$0]++\\'\" + f\" {outTxt} > {name}.motif.uniq.txt\"\n",
    "    print(line)\n",
    "    os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2.motif.tmp.txt   1_5.motif.tmp.txt\tHK2.all.1_2.new.heat.bed\r\n",
      "1_2.motif.txt\t    1_5.motif.txt\tHK2.all.1_2.sig.anno.txt\r\n",
      "1_2.motif.uniq.txt  1_5.motif.uniq.txt\tHK2.all.1_5.new.heat.bed\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 look for enriched motifs in wild type ENL binding peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t858702\t861593\tMACS_peak_1\t1093.75\n",
      "chr1\t870327\t871455\tMACS_peak_2\t97.85\n",
      "chr1\t875392\t878559\tMACS_peak_3\t676.52\n",
      "chr1\t932422\t936620\tMACS_peak_4\t1067.60\n",
      "chr1\t955250\t956213\tMACS_peak_5\t86.76\n",
      "chr1\t1709153\t1710245\tMACS_peak_6\t94.82\n",
      "chr1\t1821251\t1822759\tMACS_peak_7\t346.39\n",
      "chr1\t2159906\t2163136\tMACS_peak_8\t1053.44\n",
      "chr1\t2245753\t2246888\tMACS_peak_9\t88.14\n",
      "chr1\t3568419\t3569644\tMACS_peak_10\t98.29\n",
      "3298 /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed\n"
     ]
    }
   ],
   "source": [
    "!head /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed\n",
    "!wc -l /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed\n",
    "!cp /mount/weili3/xc3/ENL2_ChIP/res_nsp_lambda/293_F_ENL.nsp_peaks.bed  ./\n",
    "!mv 293_F_ENL.nsp_peaks.bed ENL.motif.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed ENL.motif.bed -fo ENL.motif.txt\n",
      "awk '!a[$0]++' ENL.motif.txt > ENL.motif.uniq.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'ENL'\n",
    "bedFile = f'{name}.motif.bed'\n",
    "outTxt = f'{name}.motif.txt'\n",
    "line = f\"bedtools getfasta -fi /mount/weili3/xc3/genomes/hg19_trim.fa -bed {bedFile} -fo {outTxt}\"\n",
    "print(line)\n",
    "os.system(line)\n",
    "line = \"awk \\'!a[$0]++\\'\" + f\" {outTxt} > {name}.motif.uniq.txt\"\n",
    "print(line)\n",
    "os.system(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_coup_peaks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "os.chdir('/home/xc3/experiment/ENL2/Chip-seq_analysis/no_spike_in/re_do_mapping_with_lambda/res_heatmap_coup_peaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test all the pre-binding peaks signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw',\n",
       " '/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw',\n",
       " '/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw',\n",
       " '/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw',\n",
       " '/home/xc3/output/ENL2/ChIP/bw_nsp/293_F_Y78A_treat.nsp.bw']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t8482987\t8484389\r\n",
      "chr1\t15943726\t15944596\r\n",
      "chr1\t16173761\t16176666\r\n",
      "chr1\t26734734\t26735700\r\n",
      "chr1\t27286358\t27287134\r\n",
      "chr1\t38229600\t38230601\r\n",
      "chr1\t57043618\t57045418\r\n",
      "chr1\t61547212\t61550060\r\n",
      "chr1\t65431315\t65432543\r\n",
      "chr1\t78097423\t78099183\r\n"
     ]
    }
   ],
   "source": [
    "treats = ['T1','T2','T3']\n",
    "treat = treats[0]\n",
    "ctrl = 'ENL'\n",
    "[glob.glob(bwpath+exp+'*'+treat+'*.bw')[0], glob.glob(bwpath+exp+'*'+ctrl+'*.bw')[0]]\n",
    "bed_file = f'{exp}_{treat}_WT.1_2.bed'\n",
    "!head $bed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate the signal for 293_T1_WT.1_2.bed\n",
      "writing the output --> 293_T1_WT.1_2.str.bed\n",
      "293_T1_WT.1_2.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T1_treat.nsp.bw 293_T1_WT.1_2.str.bed avg_sig_0.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw 293_T1_WT.1_2.str.bed avg_sig_1.txt\n",
      "output file -->: 293_T1_WT.1_2.counts.txt\n",
      "********\n",
      "generate the signal for 293_T2_WT.1_2.bed\n",
      "writing the output --> 293_T2_WT.1_2.str.bed\n",
      "293_T2_WT.1_2.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T2_treat.nsp.bw 293_T2_WT.1_2.str.bed avg_sig_0.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw 293_T2_WT.1_2.str.bed avg_sig_1.txt\n",
      "output file -->: 293_T2_WT.1_2.counts.txt\n",
      "********\n",
      "generate the signal for 293_T3_WT.1_2.bed\n",
      "writing the output --> 293_T3_WT.1_2.str.bed\n",
      "293_T3_WT.1_2.str.bed --->: reformated bed_file as the input of the bigWigAverageoverBed\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_T3_treat.nsp.bw 293_T3_WT.1_2.str.bed avg_sig_0.txt\n",
      "execute --> ~/software/bigWigAverageOverBed /home/xc3/output/ENL2/ChIP/bw_nsp/293_F_ENL_treat.nsp.bw 293_T3_WT.1_2.str.bed avg_sig_1.txt\n",
      "output file -->: 293_T3_WT.1_2.counts.txt\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "bwpath = '/home/xc3/output/ENL2/ChIP/bw_nsp/'\n",
    "exp = '293'\n",
    "bwfiles.sort()\n",
    "for treat in treats:\n",
    "    bed_file = f'{exp}_{treat}_WT.1_2.bed'\n",
    "    bwfiles = [glob.glob(bwpath+exp+'*'+treat+'*.bw')[0],\n",
    "          glob.glob(bwpath+exp+'*'+ctrl+'*.bw')[0]]\n",
    "    print('generate the signal for',bed_file)\n",
    "    comp_avg_sig_from_bw_by_bed(bed_file, bwfiles, 3)\n",
    "    print('********'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('1_2.peak.sig.txt', sep='\\t')\n",
    "df = pd.read_csv('293_T1_WT.1_2.counts.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fc'] = df.iloc[:,-2].div(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>width</th>\n",
       "      <th>293_F_T1_treat</th>\n",
       "      <th>293_F_ENL_treat</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chr, start, end, width, 293_F_T1_treat, 293_F_ENL_treat, fc]\n",
       "Index: []"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['fc'] < 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwpath = '/home/xc3/output/ENL2/ChIP/bw_nsp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
